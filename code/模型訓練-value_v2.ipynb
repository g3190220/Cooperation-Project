{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608f9531-d9c0-47a4-bf7b-fcfe91992f8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 幾種思路"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae267fd-f953-442a-88cc-e2bfb9aff87d",
   "metadata": {},
   "source": [
    "思路1：TF-IDF + 機器學習分類器\n",
    "直接使用TF-IDF對文本提取特徵，並使用分類器進行分類。在分類器的選擇上，可以使用SVM、LR、或者XGBoost。\n",
    "\n",
    "思路2：FastText\n",
    "FastText是入門款的詞向量，利用Facebook提供的FastText工具，可以快速構建出分類器。\n",
    "\n",
    "思路3：WordVec + 深度學習分類器\n",
    "WordVec是進階款的詞向量，並通過構建深度學習分類完成分類。深度學習分類的網絡結構可以選擇TextCNN、TextRNN或者BiLSTM。\n",
    "\n",
    "思路4：Bert詞向量\n",
    "Bert是高配款的詞向量，具有強大的建模學習能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10abf616-467b-4883-8210-339068693e2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 獲取6種模型的資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3f1556b9-10a8-4230-910e-2e0851184854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "path = '../data/0414/review_data(seg+pos+stopwords)_n+v+f+p.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03134552-b205-4ba6-8b30-49d1b63f6e8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 檢查重複值、空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cf01f08b-66b4-48dc-b539-f963be31ec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [reviews, value, comfort, location, cleanliness, service, facilities, ws_pos_reviews, filtered, filtered_word]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#印出重複資料\n",
    "print(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1fcd3385-74b6-4e0e-8a68-48f139e3161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#移除重複值\n",
    "#df = df.drop_duplicates()\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "57541fcf-3859-4b9d-a6af-68c3a1b7a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#印出空值資料\n",
    "#df_train[df_train.isnull().T.any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2dd09-a1d4-408b-af22-a11cdd6829a9",
   "metadata": {},
   "source": [
    "### 切分為6個資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e466b400-44e6-442f-914f-148dc9f2cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    df_value = df[['value','filtered_word']]\n",
    "    df_value.rename(columns={'value': 'label'}, inplace=True)\n",
    "    df_comfort = df[['comfort','filtered_word']]\n",
    "    df_comfort.rename(columns={'comfort': 'label'}, inplace=True)\n",
    "    df_location = df[['location','filtered_word']]\n",
    "    df_location.rename(columns={'location': 'label'}, inplace=True)\n",
    "    df_cleanliness = df[['cleanliness','filtered_word']]\n",
    "    df_cleanliness.rename(columns={'cleanliness': 'label'}, inplace=True)\n",
    "    df_service = df[['service','filtered_word']]\n",
    "    df_service.rename(columns={'service': 'label'}, inplace=True)\n",
    "    df_facilities = df[['facilities','filtered_word']]\n",
    "    df_facilities.rename(columns={'facilities': 'label'}, inplace=True)\n",
    "    return df_value, df_comfort, df_location, df_cleanliness, df_service, df_facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f74887e2-a787-4bba-af45-b6824ebbf6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_value_train, df_comfort_train, df_location_train, df_cleanliness_train, df_service_train ,df_facilities_train = split_df(df_train)\n",
    "#df_value_test, df_comfort_test, df_location_test, df_cleanliness_test, df_service_test, df_facilities_test = split_df(df_test)\n",
    "df_value, df_comfort, df_location, df_cleanliness, df_service ,df_facilities = split_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bbc20206-24d9-43f4-96c9-ab61f326eec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filtered_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>價格(Na),合理(VH),舒適(VH),房間(Nc),老闆娘(Na),人(Na),好(VH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>內部(Ncd),房間(Nc),乾淨(VH),場地(Na),團體(Na),使用(VC),覺得(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>房間(Nc),小(VH),美中不足(VH),乾(VH),濕(VH),分離(VHC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>房子(Na),設計(VC),棒(VH),房間(Nc),採光(Na),好(VH),大廳(Nc)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Cp值(FW),高(VH),乾淨(VH),舒適(VH),空間(Na),大樓(Na),下(Nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>港式(Na),飲茶(VA),餐廳(Nc),口味(Na),棒(VH),環境(Na),乾淨(VH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>場地(Na),氣派(Na),丁香魚(Na),酥脆(VH),服務(VC),親切(VH),蠟味(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>交通(Na),方便(VH),地下室(Nc),停車場(Nc),良好(VH),菜色(Na),好(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>地點(Na),佳(VH),離(P),逢甲(Nb),夜市(Nc),老闆娘(Na),親切(VH)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1.0</td>\n",
       "      <td>房間(Nc),乾淨(VH),價格(Na),公道(VH),老闆娘(Na),親切(VH),逢甲(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                      filtered_word\n",
       "0       1.0  價格(Na),合理(VH),舒適(VH),房間(Nc),老闆娘(Na),人(Na),好(VH...\n",
       "1       0.0  內部(Ncd),房間(Nc),乾淨(VH),場地(Na),團體(Na),使用(VC),覺得(...\n",
       "2       0.0          房間(Nc),小(VH),美中不足(VH),乾(VH),濕(VH),分離(VHC)\n",
       "3       1.0  房子(Na),設計(VC),棒(VH),房間(Nc),採光(Na),好(VH),大廳(Nc)...\n",
       "4       1.0  Cp值(FW),高(VH),乾淨(VH),舒適(VH),空間(Na),大樓(Na),下(Nc...\n",
       "...     ...                                                ...\n",
       "1267    0.0  港式(Na),飲茶(VA),餐廳(Nc),口味(Na),棒(VH),環境(Na),乾淨(VH...\n",
       "1268    0.0  場地(Na),氣派(Na),丁香魚(Na),酥脆(VH),服務(VC),親切(VH),蠟味(...\n",
       "1269    0.0  交通(Na),方便(VH),地下室(Nc),停車場(Nc),良好(VH),菜色(Na),好(...\n",
       "1270    0.0  地點(Na),佳(VH),離(P),逢甲(Nb),夜市(Nc),老闆娘(Na),親切(VH)...\n",
       "1271    1.0  房間(Nc),乾淨(VH),價格(Na),公道(VH),老闆娘(Na),親切(VH),逢甲(...\n",
       "\n",
       "[1272 rows x 2 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ec4bf-a42d-406c-a15e-54431ef328fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 清理資料(移除詞性標註的文字)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2cb95288-72e7-4508-aa53-1684ff8a63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_N_comma(sentence):\n",
    "    # 把後面(N..)(V..)(F..)拿掉\n",
    "    sentence = str(sentence)\n",
    "    pattern = re.compile(r\"\\([N,V,F,P].*?\\)\") #移除詞性標示\n",
    "    sentence = re.sub(pattern, '', sentence)\n",
    "    pattern = re.compile(r\",\") #將逗號替換為空格\n",
    "    sentence = re.sub(pattern, ' ', sentence)\n",
    "    return sentence\n",
    "pd.options.mode.chained_assignment = None  # 忽略警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f29d4e13-b275-406a-96c1-fd46f70772bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練集\n",
    "df_value['filtered_word'] = df_value.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "96657345-dcdf-40d4-b09b-2904f3ea0281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1272, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filtered_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>價格 合理 舒適 房間 老闆娘 人 好 做 早餐 旅客 重點 早餐 吃到飽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>內部 房間 乾淨 場地 團體 使用 覺得 棒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>房間 小 美中不足 乾 濕 分離</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>房子 設計 棒 房間 採光 好 大廳 挑高 氣派 房價 合理 台東 住 民宿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Cp值 高 乾淨 舒適 空間 大樓 下 免費 吐司 咖啡 老闆 回復 速度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>港式 飲茶 餐廳 口味 棒 環境 乾淨 機車 汽車 停車位 位於 高鐵 附近 適合 宴客</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>場地 氣派 丁香魚 酥脆 服務 親切 蠟味 蘿蔔糕 份量 一些 好 牛肉粥 好吃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>交通 方便 地下室 停車場 良好 菜色 好 空間 設計好 說 一流 飯店</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>地點 佳 離 逢甲 夜市 老闆娘 親切 服務 房間 舒適 浴室 乾淨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1.0</td>\n",
       "      <td>房間 乾淨 價格 公道 老闆娘 親切 逢甲 推 民宿 推</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                 filtered_word\n",
       "0       1.0         價格 合理 舒適 房間 老闆娘 人 好 做 早餐 旅客 重點 早餐 吃到飽\n",
       "1       0.0                        內部 房間 乾淨 場地 團體 使用 覺得 棒\n",
       "2       0.0                              房間 小 美中不足 乾 濕 分離\n",
       "3       1.0        房子 設計 棒 房間 採光 好 大廳 挑高 氣派 房價 合理 台東 住 民宿\n",
       "4       1.0         Cp值 高 乾淨 舒適 空間 大樓 下 免費 吐司 咖啡 老闆 回復 速度\n",
       "...     ...                                           ...\n",
       "1267    0.0  港式 飲茶 餐廳 口味 棒 環境 乾淨 機車 汽車 停車位 位於 高鐵 附近 適合 宴客\n",
       "1268    0.0      場地 氣派 丁香魚 酥脆 服務 親切 蠟味 蘿蔔糕 份量 一些 好 牛肉粥 好吃\n",
       "1269    0.0          交通 方便 地下室 停車場 良好 菜色 好 空間 設計好 說 一流 飯店\n",
       "1270    0.0            地點 佳 離 逢甲 夜市 老闆娘 親切 服務 房間 舒適 浴室 乾淨\n",
       "1271    1.0                  房間 乾淨 價格 公道 老闆娘 親切 逢甲 推 民宿 推\n",
       "\n",
       "[1272 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_value.shape)\n",
    "df_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b21127-7864-4ea5-bbc6-872b5ce25697",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 模型架構"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f5dea5-298a-4819-8ac5-520b79eb20c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 套件引用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9f68cb11-c4ef-4366-9a3f-9af34c9dd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import package\n",
    "#轉向量用\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pickle #儲存模型用\n",
    "from sklearn.model_selection import train_test_split\n",
    "#類別採樣\n",
    "import imblearn.over_sampling as over_sampling\n",
    "import imblearn.under_sampling as under_sampling\n",
    "import imblearn.combine as combine\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "\n",
    "\n",
    "#模型\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "#模型效能表現\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bca335-929e-46d6-b8e6-447621d41d8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 顯示訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9ad34b64-c7c9-4cce-8b62-0a266a165a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(y_test, pre):\n",
    "    #混淆矩陣\n",
    "    confusion = metrics.confusion_matrix(y_test, pre)\n",
    "    TP = confusion[1,1]\n",
    "    TN = confusion[0,0]\n",
    "    FP = confusion[0,1]\n",
    "    FN = confusion[1,0]\n",
    "    print(\"TP:\",TP)\n",
    "    print(\"TN:\",TN)\n",
    "    print(\"FP:\",FP)\n",
    "    print(\"FN:\",FN)\n",
    "    #Accuracy\n",
    "    accuracy = (TP+TN)/float(TP+TN+FN+FP)\n",
    "    print(\"Accuracy：\", accuracy)\n",
    "    #Sensitivity(Recall)\n",
    "    recall = TP/float(TP+FN)\n",
    "    print(\"Recall：\", recall)\n",
    "    #Specificity\n",
    "    specificity = TN/float(TN+FP)\n",
    "    print(\"Specificity：\", specificity)\n",
    "    #Precision\n",
    "    precision = TP/float(TP+FP)\n",
    "    print(\"Precision：\", precision)\n",
    "    #f1-score\n",
    "    f1_score = ((2*precision*recall)/(precision+recall))\n",
    "    print(\"f1_score：\", f1_score)\n",
    "    #AUC\n",
    "    print(\"AUC：\", metrics.roc_auc_score(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c37f894c-b179-4711-92b8-6e86c3c15e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filtered_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>價格 合理 舒適 房間 老闆娘 人 好 做 早餐 旅客 重點 早餐 吃到飽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>內部 房間 乾淨 場地 團體 使用 覺得 棒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>房間 小 美中不足 乾 濕 分離</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>房子 設計 棒 房間 採光 好 大廳 挑高 氣派 房價 合理 台東 住 民宿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Cp值 高 乾淨 舒適 空間 大樓 下 免費 吐司 咖啡 老闆 回復 速度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0.0</td>\n",
       "      <td>港式 飲茶 餐廳 口味 棒 環境 乾淨 機車 汽車 停車位 位於 高鐵 附近 適合 宴客</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>場地 氣派 丁香魚 酥脆 服務 親切 蠟味 蘿蔔糕 份量 一些 好 牛肉粥 好吃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>0.0</td>\n",
       "      <td>交通 方便 地下室 停車場 良好 菜色 好 空間 設計好 說 一流 飯店</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>地點 佳 離 逢甲 夜市 老闆娘 親切 服務 房間 舒適 浴室 乾淨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>1.0</td>\n",
       "      <td>房間 乾淨 價格 公道 老闆娘 親切 逢甲 推 民宿 推</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                 filtered_word\n",
       "0       1.0         價格 合理 舒適 房間 老闆娘 人 好 做 早餐 旅客 重點 早餐 吃到飽\n",
       "1       0.0                        內部 房間 乾淨 場地 團體 使用 覺得 棒\n",
       "2       0.0                              房間 小 美中不足 乾 濕 分離\n",
       "3       1.0        房子 設計 棒 房間 採光 好 大廳 挑高 氣派 房價 合理 台東 住 民宿\n",
       "4       1.0         Cp值 高 乾淨 舒適 空間 大樓 下 免費 吐司 咖啡 老闆 回復 速度\n",
       "...     ...                                           ...\n",
       "1267    0.0  港式 飲茶 餐廳 口味 棒 環境 乾淨 機車 汽車 停車位 位於 高鐵 附近 適合 宴客\n",
       "1268    0.0      場地 氣派 丁香魚 酥脆 服務 親切 蠟味 蘿蔔糕 份量 一些 好 牛肉粥 好吃\n",
       "1269    0.0          交通 方便 地下室 停車場 良好 菜色 好 空間 設計好 說 一流 飯店\n",
       "1270    0.0            地點 佳 離 逢甲 夜市 老闆娘 親切 服務 房間 舒適 浴室 乾淨\n",
       "1271    1.0                  房間 乾淨 價格 公道 老闆娘 親切 逢甲 推 民宿 推\n",
       "\n",
       "[1272 rows x 2 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8636ec-e7a7-433b-a876-342010132df4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 切分訓練、測試數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ce72c298-701c-4007-9cff-6555b3c30490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_label(df,seed):\n",
    "    X = df.filtered_word.tolist()\n",
    "    y = df.label\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=1/3,random_state=seed)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "936320a6-0c24-47de-8acb-13d32d05d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1,X_test_1,y_train_1,y_test_1 = split_label(df_value,1)\n",
    "X_train_2,X_test_2,y_train_2,y_test_2 = split_label(df_value,2)\n",
    "X_train_3,X_test_3,y_train_3,y_test_3 = split_label(df_value,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "25654090-f10c-4123-8506-d80314fa1c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    688\n",
      "1.0    160\n",
      "Name: label, dtype: int64\n",
      "0.0    697\n",
      "1.0    151\n",
      "Name: label, dtype: int64\n",
      "0.0    697\n",
      "1.0    151\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s1 = pd.Series(y_train_1)\n",
    "freq1 = s1.value_counts() \n",
    "print(freq1) \n",
    "s2 = pd.Series(y_train_2)\n",
    "freq2 = s2.value_counts() \n",
    "print(freq2) \n",
    "s3 = pd.Series(y_train_3)\n",
    "freq3 = s3.value_counts() \n",
    "print(freq3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fee28-9feb-4801-bb55-f2e537ac12d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 模型設計"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c74e39-1bbe-4c80-ad06-0e3074ae7329",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### (1) baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4effeedd-3a62-4931-a963-d0cdae920390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model(X_train,X_test,y_train,y_test):\n",
    "    print(\"SVM baseline\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(max_df=0.8,min_df=5,dtype=np.float32), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "582d7fde-ba62-4a98-9725-9d770485c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_model(X_train,X_test,y_train,y_test):\n",
    "    print(\"LR baseline\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(max_df=0.8,min_df=5,dtype=np.float32), LogisticRegression(random_state=0))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "80043705-9df6-43de-a64a-bfa8f2ea4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(X_train,X_test,y_train,y_test):\n",
    "    print(\"RF baseline\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(max_df=0.8,min_df=5,dtype=np.float32), RandomForestClassifier(max_depth=2, random_state=0))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ef4c1d09-9c26-489a-b946-f3eb16cdca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model(X_train,X_test,y_train,y_test):\n",
    "    print(\"AdaBoost_model\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), AdaBoostClassifier(n_estimators=200))\n",
    "    model.fit(X_train, y_train)\n",
    "    feature_names = model.named_steps[\"tfidfvectorizer\"].get_feature_names()\n",
    "    print(feature_names)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "50171187-5ee5-4eb3-866f-5d4fd8e06710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost_model\n",
      "['00', '10', '100', '1025', '12', '1200', '14樓', '1700', '180', '1樓', '200', '201', '2160', '2250', '24', '24h', '25', '2500', '2樓', '30', '300', '400', '50', '500', '550', '5800', '5星級', '600', '711', '80', '800', '80年', '8點', '900', '9900', '9oo', '9點半', 'agoda', 'bb', 'buffet', 'cp', 'cp值', 'diy', 'freebar', 'ktv', 'nice', 'ok', 'ps', 'spa', 'wifi', 'xd', 'ㄧ些', '一下', '一些', '一千', '一半', '一品', '一家人', '一望無際', '一樓', '一次性', '一流', '一清二楚', '一級', '一級棒', '一點', '一點點', '丁香魚', '三五', '三合一', '三四', '三明治', '三樓', '三溫暖', '三義', '三龜', '上心', '上鎖', '上限', '下來', '下午茶', '下去', '下樓', '下降', '下雨天', '不佳', '不便', '不值', '不到', '不理', '不耐煩', '不良', '不行', '不足', '不遠', '不錯', '世界', '世紀', '丟臉', '中國風', '中央', '中心', '中心點', '中正', '中班', '中繼站', '中華', '中餐', '中餐廳', '丹麥', '主人', '主人家', '主動', '主題', '主題房', '久侯', '久坐', '之後', '九份', '乳豬', '乾乾淨淨', '乾凈', '乾淨', '乾濕', '乾老闆', '事項', '二樓', '二館', '五星級', '交流道', '交給', '交誼廳', '交通', '享受', '享用', '人員', '人工', '人情味', '人房', '人潮', '人間', '今天', '今日', '介紹', '介紹給', '付費', '付錢', '仙境', '仙草', '代替', '代步', '代訂', '仰望', '份量', '休息', '休息區', '休閒', '佈置', '位子', '位於', '位置', '低海拔', '低音', '低頻', '住在', '住宅區', '住客', '住家', '住宿', '住宿區', '住宿費', '住所', '住起來', '佩佩', '使用', '來來', '來到', '來客', '來此', '供應', '便利', '便利商店', '便利性', '便宜', '便當', '保護區', '保養', '信息', '修好', '俯瞰', '個性', '倒光', '倒閉', '值得', '假日', '假期', '偏上', '偏向', '偏遠', '做做', '停滿', '停車', '停車位', '停車場', '健談', '健身室', '健身房', '偷肉', '備品', '備品量', '備有', '傳統', '傳藝', '價位', '價值', '價廉', '價格', '價錢', '優勢', '優惠', '優格', '優美', '優良', '優遊', '優雅', '優點', '充滿', '充足', '充電線', '先生', '光臨', '免費', '兒子', '兒童', '兔子', '入住', '入味', '入睡', '內外', '內容', '內涵', '內部', '全家', '全新', '全聯', '公共區', '公園', '公尺', '公廁', '公益路', '公車', '公車站', '公道', '六七', '六合', '六星', '六星級', '六福村', '共享', '共用', '具有', '典雅', '冬天', '冬瓜', '冰淇淋', '冰箱', '冷凍', '冷氣', '冷氣室', '冷盤', '冷菜', '凱特', '出國', '出差', '出租', '出租給', '出菜', '出遊', '出錢', '出門', '分享', '分鐘', '分開', '分離', '切仔麵', '划算', '別墅', '到位', '到訪', '前來', '前往', '前面', '創作', '功能', '加價', '加大', '加大房', '加強', '加收', '加溫', '加蓋', '動物', '動物區', '勤快', '包含', '包子', '包廂', '包木屋', '化妝', '北下', '北海岸', '北竿', '北車', '北部', '區域', '十一點', '十足', '升等', '午餐', '協助', '南瓜粥', '南點', '博學', '卡片', '印度', '危險', '厚片', '原住民', '原木', '去處', '參加', '參考', '及格', '友善', '取消', '取用', '叢叢', '口味', '口感', '口福', '口袋', '古樸', '古色古香', '可口', '可惜', '可愛', '可親', '台中', '台北', '台北市', '台南', '台南市', '台東', '台東市', '台灣', '台灣人', '台灣版', '司機', '吃到', '吃到飽', '吃完', '吃遍', '吃飯', '合作', '合法', '合理', '合菜', '同事', '名單', '名字', '名宿', '吐司', '吧台', '吵到', '吵雜', '吵雜聲', '吵麻煩', '吸引進去', '吸菸', '吹頭', '吹風機', '呆板', '告知', '告訴', '周到', '周圍', '周遭', '周邊', '味道', '和善', '和氣', '和藹', '和藹可親', '咖啡', '咖啡包', '咖啡廳', '咖啡機', '品牌', '品質', '哈士奇', '哈瑪星', '員工', '唬爛', '售價', '唱歌', '商務', '商圈', '商場', '商家', '商旅', '問話', '問題', '善有', '喇叭', '喜宴', '喜愛', '喜歡', '喧嘩', '單人', '單人床', '單品', '單薄', '單車', '單車族', '嘉義', '噪音', '囉嗦', '四人房', '四捨五入', '回住', '回到', '回家', '回復', '回歸線', '回答', '回覆', '回訪', '國家級', '國民', '國華街', '國賓', '圍爐', '圍繞', '園區', '團聚', '團隊', '團體', '土司', '在一起', '在來', '在地', '在地人', '在意', '地上', '地下室', '地中海', '地區', '地圖', '地方', '地板', '地理', '地瓜', '地瓜籤', '地瓜粥', '地瓜葉', '地點', '坐坐', '垃圾袋', '城堡', '埔里', '基督徒', '基隆', '基隆山', '堜啡', '堤防', '場地', '塞車', '塵囂', '增加', '壁畫', '壁紙', '壽司', '夏天', '夏日', '夕陽', '夕陽西下', '外借', '外出', '外加', '外帶', '外表', '外觀', '外送', '外部', '外面', '多元', '多意思', '多樣', '多樣化', '多聞', '夜市', '夜店', '夜晚', '夜景', '大人', '大台北', '大哥', '大姊', '大小', '大廳', '大推', '大方', '大早餐', '大樓', '大港橋', '大直', '大眾池', '大自然', '大車', '大道', '大部分', '大門', '大鵬灣橋', '天井', '天台', '天堂', '天氣', '天空', '天花板', '太多', '太平山', '太陽', '夫妻', '夭壽', '套房', '套餐', '女兒', '女生', '奶奶', '奶茶', '好友', '好吃', '好喝', '好好', '好好玩', '好客', '好幾', '好找', '好拍', '好極了', '好玩', '好用', '如同', '姐姐', '委任', '娃娃', '婆婆', '婚宴', '媲美', '媽媽', '嬰兒', '孔雀', '季節', '孩子', '學校', '學生', '安全', '安平', '安平港', '安心', '安排', '安靜', '完備', '完善', '完美', '完食', '官網', '定價', '宛如', '宜蘭', '客人', '客家人', '客廳', '客房', '客服', '客氣', '客運站', '室內机', '宴客', '宵夜', '家人', '家具', '家大版', '家庭', '家庭房', '家族', '家長', '宿舍', '寄回', '寄回家', '寄居蟹', '寄舖', '密境', '富有', '寢具', '寢時', '實在', '實惠', '實際', '寧夏', '寧靜', '寬廣', '寬敞', '寬闊', '寵物', '寶貝', '專區', '專屬', '專業', '專業型', '專業級', '對待', '對面', '導覽', '小人國', '小吃', '小姐', '小孩', '小孩子', '小小孩', '小屋', '小幫手', '小店', '小強', '小心', '小推車', '小時', '小朋友', '小木屋', '小港', '小菜', '小貴', '小費', '小點', '少女心', '少數', '少有', '少見', '少許', '尚可', '尼斯', '尿騷味', '居住', '居家', '屋主', '屋頂', '屏東人', '展出', '展覽', '屬於', '山坡', '山嵐', '山明水秀', '山景', '山莊', '山陵', '岑嵐', '峨眉', '嶺頂', '川雅居', '工作', '工具', '工業', '工業風', '左右', '巨蛋', '差別', '差勁', '巴黎', '巷弄', '市中心', '市區', '市場', '布丁', '布置', '布農', '布農族', '希臘', '希臘風', '師傅', '帶土味', '幫忙', '幫手', '干淨', '平價', '平日', '平易近人', '平面', '年代', '年紀', '年輕', '幽靜', '幽默', '床位', '床單', '床埔', '床墊', '床鋪', '床頭', '店員', '店家', '度假', '座位', '座位區', '庭園', '庭院', '廁所', '廚具', '廚房', '廣場', '廣大', '建築', '建議', '形式', '彩繪', '彰化', '影片', '影響', '待人', '待客', '後悔', '後方', '後面', '得到', '微波爐', '德國', '德陽', '心思', '心情', '心靈', '忘記', '快速', '怕生', '思旅', '怡人', '性價比', '性情', '怪味', '恆春', '恐怖', '悠久', '悠閒', '情人節', '情侶', '惡劣', '想像', '愉快', '意外', '意思', '意見', '愛心', '愛車', '愜意', '感受', '感受到', '感覺', '感覺出來', '感謝', '慈愛', '態度', '慢活', '懇丁', '應有盡有', '懷孕', '懷念', '成功嶺', '成功村', '成功路', '戲水', '戲水池', '戲耍', '戲院', '戶外', '房價', '房務', '房型', '房子', '房客', '房屋', '房東', '房東人', '房況', '房門', '房間', '房間數', '手作', '手工', '手捲', '手機', '手沖', '手藝', '打包', '打卡', '打呼聲', '打開', '打電話', '打麻將', '扶手', '批發', '找到', '技術', '投幣式', '披薩', '抵達', '抹醬', '拍攝', '拍照', '招待', '拜訪', '拼盤', '拿鐵', '持續', '指定', '指導', '按摩', '按摩椅', '挑剔', '挑高', '捨得', '捲筒紙', '捷運', '捷運站', '掉落', '排水', '排風', '排餐', '掖備', '採光', '接受', '接待', '接洽', '接近', '接送', '推拿', '推推', '推給', '推薦', '推薦為', '推車', '提供', '提到', '提升', '提回', '提醒', '換掉', '搞錯', '搭伙', '摔下', '摩托車', '撞球', '擁擠', '擁有', '擔心', '擺盤', '擺設', '收費', '收錢', '收養', '改善', '改成', '改用', '改裝', '放假', '放空', '放置', '放鬆', '故事', '效果', '救星', '教堂', '教學', '教練', '教育', '散客', '散步', '散發掉', '整修', '整潔', '整理', '整體', '整齊', '敷衍', '文創風', '文化', '文青', '料好', '料理', '新人', '新意', '新淨', '新穎', '新開幕', '新館', '新鮮', '方便', '方便度', '方便性', '方式', '方正', '方面', '施工', '旁邊', '旅人', '旅客', '旅店', '旅游', '旅社', '旅社級', '旅程', '旅行', '旅行社', '旅遊', '旅館', '旗山', '日出', '日文', '日月潭', '日本', '日本餐', '日落', '早上', '早班', '早起來', '早餐', '早餐吧', '早餐店', '早餐籃', '早點', '明亮', '明顯', '星星', '星期六', '星空', '春天', '時光', '時間', '晚上', '晚班', '晚餐', '普普', '普通', '景房', '景色', '景觀', '景觀台', '景觀房', '景點', '暑假', '暖和', '暖暖', '暖男', '曬曬太陽', '書籍', '最後', '會客室', '會館', '月租', '有別於', '有善', '有夠', '有待', '有無', '有禮', '有趣', '有限', '朋友', '服務', '服務元', '服務台', '服務員', '服務量', '服飾', '望出去', '期間', '木屋', '木屋區', '木板', '木頭', '未來', '杯子', '東林', '東河', '東港', '東西', '枕頭', '枕頭棒', '林立', '林默娘', '果樹', '果汁', '果醬', '柔柔', '柔軟', '柔道', '柚子', '柳橙', '格出來', '格局', '栽植', '桃園', '桌上鏡', '桌子', '桌椅', '桌球', '桌菜', '桌遊', '梳子', '棉被', '森林', '森林茶', '椅子', '植物', '椒麻雞', '楊桃', '業者', '極好', '榻榻米', '樂活', '樓上', '樓下', '樓中樓', '樓層', '樓梯', '樓梯口', '樣子', '樣式', '樸實', '樹木', '樹林', '樹薯包', '機台', '機場', '機會', '機械', '機車', '檸檬汁', '櫃台', '櫃檯', '櫃臺', '櫻花', '欠佳', '欣賞', '款待', '歐洲', '歐舒丹', '歡迎', '正對面', '正比', '步行', '步道', '歲月', '歷史', '毛小孩', '毛巾', '民宿', '民雄', '氛圍', '氣息', '氣氛', '氣泡', '氣派', '水壓', '水庫', '水果', '水果樂', '水柱', '水機', '水流', '水溫', '水煮', '水社', '水管', '水餃', '水龍頭', '永和', '求婚', '汽泡', '汽車', '沈澱', '沉默', '沐浴', '沐浴乳', '沒辦法', '沖洗區', '沙坑', '沙子', '沙拉', '沙拉區', '沙灘', '沙發', '河樂', '油膩', '油麵', '法國', '泡完', '泡湯', '泡湯區', '泡湯池', '泡澡', '泡茶', '泡茶水', '泡麵', '注意', '注重', '泰式', '泳池', '洋樓', '洗手台', '洗澡', '洗衣', '洗衣機', '洗衣間', '洗髮精', '活動', '活動中心', '活潑', '洽公', '流出來', '流浪', '浪漫', '浮潛', '浴室', '浴巾', '浴廁', '浴缸', '海景', '海浪', '海港', '海灘', '海灣', '海豚', '海邊', '海風', '海鮮', '消夜', '消毒', '消除', '淋浴', '淘氣', '深夜', '清優', '清境', '清幽', '清悠', '清新', '清楚', '清淨', '清潔', '清潔度', '清潔費', '清爽', '清理', '清靜', '減損', '渡假', '港式', '港都', '游泳池', '湖景', '湯屋', '湯汁', '湯池', '湯頭', '準備', '溜下床', '溜滑梯', '溪頭', '溫度', '溫暖', '溫柔', '溫泉', '溫泉池', '溫馨', '滑水道', '滲水', '滴下來', '滴水', '滿分', '滿意', '滿滿', '漂亮', '漂浮', '漏水', '漢堡', '漢神', '潛水', '潤滑油', '澎島', '澎湖', '濃厚', '濕地', '濕氣', '濕答答', '濾掛', '灑滿', '火車', '火車站', '火鍋', '灰塵', '炒米粉', '烘衣', '烘衣機', '烤箱', '烤肉區', '烤肉爐', '烹調', '無庸置疑', '無意', '無敵', '無比', '無聊', '無言', '無限', '煙味', '煙火', '照片', '照顧', '煮食', '煮飯', '熊貓', '熟食', '熟食區', '熱切', '熱心', '熱忱', '熱情', '熱水', '熱水器', '熱水澡', '熱沉', '熱湯', '熱熱', '熱誠', '熱門', '熱鬧', '燈光', '燈光秀', '燈籠', '燒烤', '燒餅', '燒麵', '營業', '營養', '爆表', '爛死', '父母親', '爸媽', '牆壁', '牆面', '牙刷', '牙膏', '牛奶', '牛排', '牛肉粥', '牡蠣', '牧草', '物品', '物美價廉', '特別', '特區', '特殊', '特色', '特色餐', '狀況', '狗狗', '狹小', '獨立', '獨立筒', '玩具', '玩完', '玩樂', '玩沙池', '玩瘋', '玻璃', '玻璃屋', '班機', '現代', '現場', '理想', '理髮', '瑞士', '瑞豐', '瑣碎', '環保', '環境', '環境衛生', '環島', '瓦斯爐', '甜點', '生態', '生態環境', '生活', '生菜', '生魚片', '產品', '用具', '用品', '用完', '用心', '用戶', '用料', '用餐', '田園', '申請', '留念', '略顯', '畫作', '畫工', '畫質', '異味', '當地', '當天', '疫情', '痕跡', '療癒', '發呆', '發現', '白天', '白煮蛋', '白茶', '百貨', '百貨公司', '皆大歡喜', '盛名', '盡收眼底', '盥洗', '目前', '直接', '相似', '相關', '省力', '省錢', '看出', '看出去', '看到', '看見', '真心', '真誠', '眺望', '睡眠', '睡覺', '睡起來', '瞬間', '知名', '知本', '知道', '石朗', '石門', '破損', '硬體', '碗盤', '碳烤', '確幸', '確認', '磁磚', '礁溪', '礦泉水', '社頂', '禁菸房', '禮貌', '秀麗', '秋冬', '租乘', '租借', '移車', '稀飯', '稀飯區', '程度', '種植', '種類', '穩定', '空地', '空氣', '空調', '空調聲', '空間', '空間感', '窗戶', '窩旅', '童話', '竹叉', '竹山', '竹筍包', '符合', '第一', '第三', '第二', '第六', '第四台', '等待', '等級', '算是', '管家', '管線', '簡便', '簡單', '簡易', '簡潔', '簡約', '簡陋', '米房', '粥品', '精心', '精油', '精緻', '精緻度', '精美', '精致', '糟透', '紀念堂', '紅茶', '純真', '素質', '素食', '素食區', '細心', '細節', '細緻', '結論', '絕佳', '給予', '絲毫', '經濟', '經濟房', '經營', '經理', '經驗', '綠島', '綠意盎然', '綠色', '維持', '維護', '網站', '網路', '緊鄰', '總統房', '總體', '繚繞', '繼光餅', '續冰', '缺少', '缺點', '置物', '置身', '羅東', '美中不足', '美口景', '美味', '美女', '美好', '美崙美奐', '美心', '美景', '美觀', '美食', '美麗', '美麗島站', '義大利麵', '翻新', '翻騰', '老k', '老人', '老公', '老婆', '老婆人', '老師', '老板', '老舊', '老街', '老街口', '老闆', '老闆人', '老闆娘', '考慮', '耐性', '耳傳', '聊天', '聖地', '聚所', '聚會', '聚餐', '聞到', '聯絡', '聯誼', '聲音', '聽到', '肉燥飯', '肉質', '肉醬', '肉類', '肉鬆', '肚子', '背包', '背包客', '背包客房', '腳底', '腳踏車', '臨時', '臨近', '自備', '自助', '自助式', '自助餐', '自在', '自然', '自理', '自由', '自由自在', '自種', '自行車', '自製', '臺灣', '舒服', '舒適', '舒適性', '良好', '芋圓', '芭樂', '花亭', '花俏', '花園', '花生', '花生醬', '花美男', '花蓮', '花費', '花錢', '芳香', '茶包', '茶品', '茶水', '茶水間', '茶類', '茶點', '草地', '草坪', '草皮', '草莓', '荷花池', '莊主', '莎士比亞', '菜品', '菜單', '菜園', '菜脯', '菜色', '菜餚', '華山', '華麗', '菸味', '落地窗', '落差', '落日', '蒸氣室', '蓋好', '蓋子', '蓮花', '蓮蓬頭', '蔬菜', '蔬菜量', '蔬食', '蔬食餐', '薰衣草', '藏書', '藝廊', '藝術', '藝術家', '藝術感', '藥膳', '蘋果', '蘋果花', '蘿蔔糕', '蚊子', '蚊蟲', '蛋糕', '蛋餅', '蛋黃區', '蛙鳴', '蜂蜜', '蜘蛛', '蜜香', '螃蟹', '螞蟻房', '蟑螂', '蟲鳴聲', '蠟味', '行動', '行李', '行李箱', '行李面', '行程', '街景', '街道', '衛浴', '衛生', '衛生紙盒', '衝浪屋', '衣服', '衣架', '被子', '裕園', '補充', '補助', '裝潢', '裝飾', '裡面', '製作', '襪子', '西子灣', '西曬', '西瓜', '西莎', '西門', '西門町', '西門站', '西門路', '西餐', '要價', '要求', '規劃', '視野', '親人', '親切', '親友', '親和', '親子', '親子房', '親戚', '親民', '親水', '覺得', '觀光', '觀察', '觀星', '觀星房', '觀景台', '觀賞', '解決', '解說', '訂單', '訂房', '訂房網', '訂放', '訊號', '記得', '設備', '設施', '設有', '設置', '設計', '設計到', '設計好', '設計感', '設計獎', '許多', '評價', '詢問', '試試', '詳實', '詳盡', '詳細', '認真', '誠意', '誠懇', '調整', '調酒', '講話', '謝謝', '變成', '豆漿', '豆腐乳', '豆花', '豐富', '豐盛', '豪氣', '豪華', '豬肉鍋', '豬肋排', '貓咪', '貝果', '貝殼', '負責任', '貨櫃', '販賣', '責任', '費用', '貼心', '資料', '資訊', '賓館', '質感', '購物', '購買', '贈予', '贈送', '走到', '走動', '走去', '走回', '走廊', '走走', '走路', '起司', '起床', '起跳', '超優', '超好', '超所值', '超扯', '超收', '超棒', '超正', '超炫', '超美', '超讚', '超高', '越南', '足夠', '足量', '距離', '路線', '踏踏', '踩上去', '身心', '身體', '躺下', '躺椅', '車位', '車子', '車庫', '車站', '軍艦', '軟硬', '載送', '輕軌', '輕鬆', '辦手禮', '辦理', '農場', '迎賓', '近郊', '迴音', '追求', '退房', '退還給', '送到', '透光', '透天厝', '透過', '這裡', '通往', '通知', '通道', '逛街', '速度', '造型', '造景', '造訪', '逢甲', '連假', '週六日', '週日', '週邊', '進出', '遊客', '遊戲', '遊戲室', '遊樂', '遊玩', '運動', '運河景', '過敏', '過癮', '道路聲', '道道', '遠眺', '遠處', '遠離', '適中', '適合', '適當', '選擇', '選擇性', '選項', '遺失', '遺忘', '遼闊', '那麼多', '郊遊', '部分', '部門', '都市', '都蘭', '鄉下', '鄉村風', '鄰居', '鄰近', '配上', '配備', '配合', '配料', '配置', '配菜', '酒吧', '酒店', '酥脆', '醃製', '醫藥箱', '醬料', '重回', '重慶', '重要', '重點', '野菜', '金台灣', '金山', '金蓮花', '金門', '錯過', '鏡子', '鐵捲門', '鐵道', '鑰匙', '門口', '門票', '門禁', '門鎖', '開心', '開放', '開水', '開車', '開門', '開飲機', '閣樓', '閩南', '闆娘', '防疫', '阿公', '阿姨', '阿嬤', '阿樂哈', '阿莎力', '阿里山', '附有', '附設', '附近', '降低', '限量', '陳舊', '陽台', '陽春', '隔壁', '隔天', '隔間', '隔音', '隔音窗', '障礙', '隨便', '隨和', '隨緣', '隱藏', '雅房', '雅緻', '雅致', '雙人', '雙人床', '雙人房', '雙鯉湖', '雜誌', '雞排', '難吃', '難吃醬', '難忘', '雲海', '雲霧', '零嘴', '零食', '電動車', '電子', '電影票', '電扇', '電梯', '電腦', '電蚊拍', '電視', '電話', '電風', '需求', '需要', '震動', '霉味', '露台', '露天', '露營', '露營區', '青年', '青旅', '青茶', '青菜', '靜待', '靠近', '面對', '面海房', '面湖房', '面積', '面紙', '鞋櫃', '韓國', '音樂', '音質', '音響', '頂樓', '預定', '預約', '預約制', '頭髮', '頻道', '顧客', '風光明媚', '風吹沙', '風味', '風情', '風景', '風景區', '風格', '風趣', '颱風', '飛到', '飛機', '飛鏢', '食材', '食物', '食用花', '飯店', '飯店區', '飯粥', '飯糰', '飯菜', '飲品', '飲料', '飲水', '飲水機', '飲用水', '飲茶', '飲食', '飼養', '飾品', '餅乾', '養生', '養護', '餐具', '餐卷', '餐台', '餐廳', '餐食', '餐館', '餐點', '館方', '餵食', '饅頭', '首推', '首選', '香氣', '香港人', '香濃', '香草', '香蕉', '馬乎', '馬亨亨', '馬克杯', '馬桶', '馬祖', '馬路', '騎車', '驚嘆', '驚奇', '驚豔', '髒亂', '髒污', '髒髒', '體會', '體溫', '體貼', '體驗', '高度', '高爾夫球場', '高級', '高美', '高跟鞋', '高速', '高鐵', '高雄', '高雅', '高離', '高麗菜', '鬆餅', '鬧區', '魅力', '魚船', '魚貨', '鮮美', '鮮魚湯', '鱔魚', '鱘龍魚', '鳳梨', '鴕鳥', '鵝肉亭', '鵝肝', '鹹淡', '鹽酥雞', '鹿港', '麥當勞', '麥當當', '麵包', '麵包區', '麵包子', '麵飯粥', '麻將', '麻將桌', '麻辣鍋', '黃昏', '黃黃', '黏黏', '黑狗兄', '黑糖', '點心', '點餐', '齊備', '齊全', '龍坑', '龍貓', '龜山島']\n",
      "TP: 42\n",
      "TN: 354\n",
      "FP: 7\n",
      "FN: 21\n",
      "Accuracy： 0.9339622641509434\n",
      "Recall： 0.6666666666666666\n",
      "Specificity： 0.9806094182825484\n",
      "Precision： 0.8571428571428571\n",
      "f1_score： 0.75\n",
      "AUC： 0.8236380424746075\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model(X_train_1,X_test_1,y_train_1,y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd242fc-ed52-47a3-8e8e-950263def92b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### (2)執行採樣 => 解決類別不平衡 (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "de9840cc-0b35-41a1-87fa-b57132a13672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model2(X_train,X_test,y_train,y_test):\n",
    "    print(\"ADASYN\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.ADASYN(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b56f9250-4755-4aef-acbf-0a0e24dfefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model3(X_train,X_test,y_train,y_test):\n",
    "    print(\"SMOTE\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.SMOTE(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "17634123-3d47-49b6-aecd-e949c4226cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model4(X_train,X_test,y_train,y_test):\n",
    "    print(\"RandomOverSampler\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.RandomOverSampler(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e0c4654d-5f7a-474a-adb0-e151c3eaffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model5(X_train,X_test,y_train,y_test):\n",
    "    print(\"RandomUnderSampler\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), under_sampling.RandomUnderSampler(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a3f1f-a2b0-444d-8c27-09e25477c011",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### (3)執行採樣 => 解決類別不平衡 (Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ccdebd6-b168-4328-b945-d6a3f5bb6727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model2(X_train,X_test,y_train,y_test):\n",
    "    print(\"ADASYN\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.ADASYN(), AdaBoostClassifier(n_estimators=200))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c73e184-3030-4ca2-be1e-62bd33ccfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model3(X_train,X_test,y_train,y_test):\n",
    "    print(\"SMOTE\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.SMOTE(), AdaBoostClassifier(n_estimators=200))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1284a043-f531-4f0c-b810-79505df5608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model4(X_train,X_test,y_train,y_test):\n",
    "    print(\"RandomOverSampler\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.RandomOverSampler(), AdaBoostClassifier(n_estimators=200))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9bebfbf5-6b8f-4a97-b1b7-c7e664be046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model5(X_train,X_test,y_train,y_test):\n",
    "    print(\"RandomUnderSampler\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), under_sampling.RandomUnderSampler(), AdaBoostClassifier(n_estimators=200))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d93f4-b593-4079-a7ee-50106af14326",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 模型訓練&結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87038cb-fcf0-487b-be81-3b9ed8ac340d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 資料集1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307939ac-c4f2-4bfb-a2c3-4bd0022e34c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a8b3b39-db3f-4b2f-b9b1-f160fc1c2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline\n",
      "TP: 37\n",
      "TN: 359\n",
      "FP: 2\n",
      "FN: 26\n",
      "Accuracy： 0.9339622641509434\n",
      "Recall： 0.5873015873015873\n",
      "Specificity： 0.9944598337950139\n",
      "Precision： 0.9487179487179487\n",
      "f1_score： 0.7254901960784315\n",
      "AUC： 0.7908807105483007\n",
      "\n",
      "\n",
      "LR baseline\n",
      "TP: 14\n",
      "TN: 361\n",
      "FP: 0\n",
      "FN: 49\n",
      "Accuracy： 0.8844339622641509\n",
      "Recall： 0.2222222222222222\n",
      "Specificity： 1.0\n",
      "Precision： 1.0\n",
      "f1_score： 0.3636363636363636\n",
      "AUC： 0.6111111111111112\n",
      "\n",
      "\n",
      "RF baseline\n",
      "TP: 0\n",
      "TN: 361\n",
      "FP: 0\n",
      "FN: 63\n",
      "Accuracy： 0.8514150943396226\n",
      "Recall： 0.0\n",
      "Specificity： 1.0\n",
      "Precision： nan\n",
      "f1_score： nan\n",
      "AUC： 0.5\n",
      "\n",
      "\n",
      "AdaBoost_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_24784/3777238089.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  precision = TP/float(TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 42\n",
      "TN: 356\n",
      "FP: 5\n",
      "FN: 21\n",
      "Accuracy： 0.9386792452830188\n",
      "Recall： 0.6666666666666666\n",
      "Specificity： 0.9861495844875346\n",
      "Precision： 0.8936170212765957\n",
      "f1_score： 0.7636363636363636\n",
      "AUC： 0.8264081255771005\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "LR_model(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "RF_model(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "AdaBoost_model(X_train_1,X_test_1,y_train_1,y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f57e29b-b5da-4c19-bd5f-66566b2866b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8927158e-6bb9-4229-baa0-9375efea894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 36\n",
      "TN: 349\n",
      "FP: 12\n",
      "FN: 27\n",
      "Accuracy： 0.9080188679245284\n",
      "Recall： 0.5714285714285714\n",
      "Specificity： 0.9667590027700831\n",
      "Precision： 0.75\n",
      "f1_score： 0.6486486486486486\n",
      "AUC： 0.7690937870993273\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 33\n",
      "TN: 351\n",
      "FP: 10\n",
      "FN: 30\n",
      "Accuracy： 0.9056603773584906\n",
      "Recall： 0.5238095238095238\n",
      "Specificity： 0.9722991689750693\n",
      "Precision： 0.7674418604651163\n",
      "f1_score： 0.6226415094339623\n",
      "AUC： 0.7480543463922965\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 35\n",
      "TN: 350\n",
      "FP: 11\n",
      "FN: 28\n",
      "Accuracy： 0.9080188679245284\n",
      "Recall： 0.5555555555555556\n",
      "Specificity： 0.9695290858725761\n",
      "Precision： 0.7608695652173914\n",
      "f1_score： 0.6422018348623854\n",
      "AUC： 0.7625423207140659\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 42\n",
      "TN: 312\n",
      "FP: 49\n",
      "FN: 21\n",
      "Accuracy： 0.8349056603773585\n",
      "Recall： 0.6666666666666666\n",
      "Specificity： 0.8642659279778393\n",
      "Precision： 0.46153846153846156\n",
      "f1_score： 0.5454545454545455\n",
      "AUC： 0.7654662973222529\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model2(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "SVM_model3(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "SVM_model4(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "SVM_model5(X_train_1,X_test_1,y_train_1,y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104f3fb-c135-4b1c-a4e9-f2523310eb9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49c81a34-8472-4d71-bbef-d69983019057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 43\n",
      "TN: 338\n",
      "FP: 23\n",
      "FN: 20\n",
      "Accuracy： 0.8985849056603774\n",
      "Recall： 0.6825396825396826\n",
      "Specificity： 0.9362880886426593\n",
      "Precision： 0.6515151515151515\n",
      "f1_score： 0.6666666666666666\n",
      "AUC： 0.8094138855911709\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 42\n",
      "TN: 344\n",
      "FP: 17\n",
      "FN: 21\n",
      "Accuracy： 0.910377358490566\n",
      "Recall： 0.6666666666666666\n",
      "Specificity： 0.9529085872576177\n",
      "Precision： 0.711864406779661\n",
      "f1_score： 0.6885245901639344\n",
      "AUC： 0.8097876269621421\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 42\n",
      "TN: 344\n",
      "FP: 17\n",
      "FN: 21\n",
      "Accuracy： 0.910377358490566\n",
      "Recall： 0.6666666666666666\n",
      "Specificity： 0.9529085872576177\n",
      "Precision： 0.711864406779661\n",
      "f1_score： 0.6885245901639344\n",
      "AUC： 0.8097876269621421\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 40\n",
      "TN: 323\n",
      "FP: 38\n",
      "FN: 23\n",
      "Accuracy： 0.8561320754716981\n",
      "Recall： 0.6349206349206349\n",
      "Specificity： 0.8947368421052632\n",
      "Precision： 0.5128205128205128\n",
      "f1_score： 0.5673758865248226\n",
      "AUC： 0.7648287385129491\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model2(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "AdaBoost_model3(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "AdaBoost_model4(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "AdaBoost_model5(X_train_1,X_test_1,y_train_1,y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7cd266-8e91-4db7-97ca-3ceca34d9271",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 資料集2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8465954-51b1-4f56-9650-9670379c1b3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f5165c90-95d3-4716-9efa-1a87bb69310a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline\n",
      "TP: 47\n",
      "TN: 352\n",
      "FP: 0\n",
      "FN: 25\n",
      "Accuracy： 0.9410377358490566\n",
      "Recall： 0.6527777777777778\n",
      "Specificity： 1.0\n",
      "Precision： 1.0\n",
      "f1_score： 0.7899159663865547\n",
      "AUC： 0.8263888888888888\n",
      "\n",
      "\n",
      "LR baseline\n",
      "TP: 20\n",
      "TN: 352\n",
      "FP: 0\n",
      "FN: 52\n",
      "Accuracy： 0.8773584905660378\n",
      "Recall： 0.2777777777777778\n",
      "Specificity： 1.0\n",
      "Precision： 1.0\n",
      "f1_score： 0.4347826086956522\n",
      "AUC： 0.6388888888888888\n",
      "\n",
      "\n",
      "RF baseline\n",
      "TP: 0\n",
      "TN: 352\n",
      "FP: 0\n",
      "FN: 72\n",
      "Accuracy： 0.8301886792452831\n",
      "Recall： 0.0\n",
      "Specificity： 1.0\n",
      "Precision： nan\n",
      "f1_score： nan\n",
      "AUC： 0.5\n",
      "\n",
      "\n",
      "AdaBoost_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_24784/3777238089.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  precision = TP/float(TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 55\n",
      "TN: 350\n",
      "FP: 2\n",
      "FN: 17\n",
      "Accuracy： 0.9551886792452831\n",
      "Recall： 0.7638888888888888\n",
      "Specificity： 0.9943181818181818\n",
      "Precision： 0.9649122807017544\n",
      "f1_score： 0.8527131782945737\n",
      "AUC： 0.8791035353535352\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "LR_model(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "RF_model(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "AdaBoost_model(X_train_2,X_test_2,y_train_2,y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71898e-545d-4724-90ee-4c55ed7cd8bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "17549184-0a46-42ae-9291-d1d6b9f1f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 53\n",
      "TN: 342\n",
      "FP: 10\n",
      "FN: 19\n",
      "Accuracy： 0.9316037735849056\n",
      "Recall： 0.7361111111111112\n",
      "Specificity： 0.9715909090909091\n",
      "Precision： 0.8412698412698413\n",
      "f1_score： 0.7851851851851852\n",
      "AUC： 0.85385101010101\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 52\n",
      "TN: 345\n",
      "FP: 7\n",
      "FN: 20\n",
      "Accuracy： 0.9363207547169812\n",
      "Recall： 0.7222222222222222\n",
      "Specificity： 0.9801136363636364\n",
      "Precision： 0.8813559322033898\n",
      "f1_score： 0.7938931297709924\n",
      "AUC： 0.8511679292929293\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 52\n",
      "TN: 346\n",
      "FP: 6\n",
      "FN: 20\n",
      "Accuracy： 0.9386792452830188\n",
      "Recall： 0.7222222222222222\n",
      "Specificity： 0.9829545454545454\n",
      "Precision： 0.896551724137931\n",
      "f1_score： 0.7999999999999999\n",
      "AUC： 0.8525883838383838\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 58\n",
      "TN: 298\n",
      "FP: 54\n",
      "FN: 14\n",
      "Accuracy： 0.839622641509434\n",
      "Recall： 0.8055555555555556\n",
      "Specificity： 0.8465909090909091\n",
      "Precision： 0.5178571428571429\n",
      "f1_score： 0.6304347826086957\n",
      "AUC： 0.8260732323232323\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model2(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "SVM_model3(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "SVM_model4(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "SVM_model5(X_train_2,X_test_2,y_train_2,y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a1084-02ce-4dc5-85fd-3c65d6d8265c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5f696397-9819-49b2-99b8-58a2c9ccc5fa",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 51\n",
      "TN: 343\n",
      "FP: 9\n",
      "FN: 21\n",
      "Accuracy： 0.9292452830188679\n",
      "Recall： 0.7083333333333334\n",
      "Specificity： 0.9744318181818182\n",
      "Precision： 0.85\n",
      "f1_score： 0.7727272727272727\n",
      "AUC： 0.8413825757575758\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 55\n",
      "TN: 345\n",
      "FP: 7\n",
      "FN: 17\n",
      "Accuracy： 0.9433962264150944\n",
      "Recall： 0.7638888888888888\n",
      "Specificity： 0.9801136363636364\n",
      "Precision： 0.8870967741935484\n",
      "f1_score： 0.8208955223880596\n",
      "AUC： 0.8720012626262627\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 54\n",
      "TN: 343\n",
      "FP: 9\n",
      "FN: 18\n",
      "Accuracy： 0.9363207547169812\n",
      "Recall： 0.75\n",
      "Specificity： 0.9744318181818182\n",
      "Precision： 0.8571428571428571\n",
      "f1_score： 0.7999999999999999\n",
      "AUC： 0.8622159090909092\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 58\n",
      "TN: 312\n",
      "FP: 40\n",
      "FN: 14\n",
      "Accuracy： 0.8726415094339622\n",
      "Recall： 0.8055555555555556\n",
      "Specificity： 0.8863636363636364\n",
      "Precision： 0.5918367346938775\n",
      "f1_score： 0.6823529411764706\n",
      "AUC： 0.8459595959595959\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model2(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "AdaBoost_model3(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "AdaBoost_model4(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "AdaBoost_model5(X_train_2,X_test_2,y_train_2,y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a73c197-ac2c-42dd-808f-fd8fc66ba2e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 資料集3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18ad43-e437-40b1-97cf-4341df882d50",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a7a8c07-7bd3-4541-8096-f7e3d59048b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline\n",
      "TP: 44\n",
      "TN: 350\n",
      "FP: 2\n",
      "FN: 28\n",
      "Accuracy： 0.9292452830188679\n",
      "Recall： 0.6111111111111112\n",
      "Specificity： 0.9943181818181818\n",
      "Precision： 0.9565217391304348\n",
      "f1_score： 0.7457627118644068\n",
      "AUC： 0.8027146464646465\n",
      "\n",
      "\n",
      "LR baseline\n",
      "TP: 17\n",
      "TN: 352\n",
      "FP: 0\n",
      "FN: 55\n",
      "Accuracy： 0.8702830188679245\n",
      "Recall： 0.2361111111111111\n",
      "Specificity： 1.0\n",
      "Precision： 1.0\n",
      "f1_score： 0.38202247191011235\n",
      "AUC： 0.6180555555555556\n",
      "\n",
      "\n",
      "RF baseline\n",
      "TP: 0\n",
      "TN: 352\n",
      "FP: 0\n",
      "FN: 72\n",
      "Accuracy： 0.8301886792452831\n",
      "Recall： 0.0\n",
      "Specificity： 1.0\n",
      "Precision： nan\n",
      "f1_score： nan\n",
      "AUC： 0.5\n",
      "\n",
      "\n",
      "AdaBoost_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_24784/3777238089.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  precision = TP/float(TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 54\n",
      "TN: 341\n",
      "FP: 11\n",
      "FN: 18\n",
      "Accuracy： 0.9316037735849056\n",
      "Recall： 0.75\n",
      "Specificity： 0.96875\n",
      "Precision： 0.8307692307692308\n",
      "f1_score： 0.7883211678832116\n",
      "AUC： 0.859375\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "LR_model(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "RF_model(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "AdaBoost_model(X_train_3,X_test_3,y_train_3,y_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e9a68-245f-4986-b075-297e19ec9c4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "497f4234-e09b-4844-aada-ebfb0d99164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 47\n",
      "TN: 342\n",
      "FP: 10\n",
      "FN: 25\n",
      "Accuracy： 0.9174528301886793\n",
      "Recall： 0.6527777777777778\n",
      "Specificity： 0.9715909090909091\n",
      "Precision： 0.8245614035087719\n",
      "f1_score： 0.7286821705426356\n",
      "AUC： 0.8121843434343434\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 46\n",
      "TN: 342\n",
      "FP: 10\n",
      "FN: 26\n",
      "Accuracy： 0.9150943396226415\n",
      "Recall： 0.6388888888888888\n",
      "Specificity： 0.9715909090909091\n",
      "Precision： 0.8214285714285714\n",
      "f1_score： 0.7187499999999999\n",
      "AUC： 0.805239898989899\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 45\n",
      "TN: 347\n",
      "FP: 5\n",
      "FN: 27\n",
      "Accuracy： 0.9245283018867925\n",
      "Recall： 0.625\n",
      "Specificity： 0.9857954545454546\n",
      "Precision： 0.9\n",
      "f1_score： 0.7377049180327869\n",
      "AUC： 0.8053977272727273\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 53\n",
      "TN: 298\n",
      "FP: 54\n",
      "FN: 19\n",
      "Accuracy： 0.8278301886792453\n",
      "Recall： 0.7361111111111112\n",
      "Specificity： 0.8465909090909091\n",
      "Precision： 0.4953271028037383\n",
      "f1_score： 0.5921787709497207\n",
      "AUC： 0.7913510101010102\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model2(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "SVM_model3(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "SVM_model4(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "SVM_model5(X_train_3,X_test_3,y_train_3,y_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a324278d-a492-448e-8f16-8b40c028da72",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0f492523-c149-4374-b132-e706f8a97e51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 55\n",
      "TN: 342\n",
      "FP: 10\n",
      "FN: 17\n",
      "Accuracy： 0.9363207547169812\n",
      "Recall： 0.7638888888888888\n",
      "Specificity： 0.9715909090909091\n",
      "Precision： 0.8461538461538461\n",
      "f1_score： 0.802919708029197\n",
      "AUC： 0.8677398989898989\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 56\n",
      "TN: 340\n",
      "FP: 12\n",
      "FN: 16\n",
      "Accuracy： 0.9339622641509434\n",
      "Recall： 0.7777777777777778\n",
      "Specificity： 0.9659090909090909\n",
      "Precision： 0.8235294117647058\n",
      "f1_score： 0.7999999999999999\n",
      "AUC： 0.8718434343434344\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 54\n",
      "TN: 336\n",
      "FP: 16\n",
      "FN: 18\n",
      "Accuracy： 0.9198113207547169\n",
      "Recall： 0.75\n",
      "Specificity： 0.9545454545454546\n",
      "Precision： 0.7714285714285715\n",
      "f1_score： 0.7605633802816902\n",
      "AUC： 0.8522727272727273\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 60\n",
      "TN: 301\n",
      "FP: 51\n",
      "FN: 12\n",
      "Accuracy： 0.8514150943396226\n",
      "Recall： 0.8333333333333334\n",
      "Specificity： 0.8551136363636364\n",
      "Precision： 0.5405405405405406\n",
      "f1_score： 0.6557377049180328\n",
      "AUC： 0.844223484848485\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model2(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "AdaBoost_model3(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "AdaBoost_model4(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "AdaBoost_model5(X_train_3,X_test_3,y_train_3,y_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c0668-fdc5-4c35-9400-f082ac358fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
