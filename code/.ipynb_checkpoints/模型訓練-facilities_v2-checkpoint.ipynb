{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608f9531-d9c0-47a4-bf7b-fcfe91992f8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 幾種思路"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae267fd-f953-442a-88cc-e2bfb9aff87d",
   "metadata": {},
   "source": [
    "思路1：TF-IDF + 機器學習分類器\n",
    "直接使用TF-IDF對文本提取特徵，並使用分類器進行分類。在分類器的選擇上，可以使用SVM、LR、或者XGBoost。\n",
    "\n",
    "思路2：FastText\n",
    "FastText是入門款的詞向量，利用Facebook提供的FastText工具，可以快速構建出分類器。\n",
    "\n",
    "思路3：WordVec + 深度學習分類器\n",
    "WordVec是進階款的詞向量，並通過構建深度學習分類完成分類。深度學習分類的網絡結構可以選擇TextCNN、TextRNN或者BiLSTM。\n",
    "\n",
    "思路4：Bert詞向量\n",
    "Bert是高配款的詞向量，具有強大的建模學習能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10abf616-467b-4883-8210-339068693e2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 獲取6種模型的資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f1556b9-10a8-4230-910e-2e0851184854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "path = '../data/0414/review_data(seg+pos+stopwords)_n+v+f+p.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03134552-b205-4ba6-8b30-49d1b63f6e8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 檢查重複值、空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf01f08b-66b4-48dc-b539-f963be31ec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [reviews, value, comfort, location, cleanliness, service, facilities, ws_pos_reviews, filtered, filtered_word]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#印出重複資料\n",
    "print(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fcd3385-74b6-4e0e-8a68-48f139e3161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#移除重複值\n",
    "#df = df.drop_duplicates()\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57541fcf-3859-4b9d-a6af-68c3a1b7a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#印出空值資料\n",
    "#df_train[df_train.isnull().T.any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2dd09-a1d4-408b-af22-a11cdd6829a9",
   "metadata": {},
   "source": [
    "### 切分為6個資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e466b400-44e6-442f-914f-148dc9f2cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    df_value = df[['value','filtered_word']]\n",
    "    df_value.rename(columns={'value': 'label'}, inplace=True)\n",
    "    df_comfort = df[['comfort','filtered_word']]\n",
    "    df_comfort.rename(columns={'comfort': 'label'}, inplace=True)\n",
    "    df_location = df[['location','filtered_word']]\n",
    "    df_location.rename(columns={'location': 'label'}, inplace=True)\n",
    "    df_cleanliness = df[['cleanliness','filtered_word']]\n",
    "    df_cleanliness.rename(columns={'cleanliness': 'label'}, inplace=True)\n",
    "    df_service = df[['service','filtered_word']]\n",
    "    df_service.rename(columns={'service': 'label'}, inplace=True)\n",
    "    df_facilities = df[['facilities','filtered_word']]\n",
    "    df_facilities.rename(columns={'facilities': 'label'}, inplace=True)\n",
    "    return df_value, df_comfort, df_location, df_cleanliness, df_service, df_facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f74887e2-a787-4bba-af45-b6824ebbf6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_3316/3099386144.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_value.rename(columns={'value': 'label'}, inplace=True)\n",
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_3316/3099386144.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_comfort.rename(columns={'comfort': 'label'}, inplace=True)\n",
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_3316/3099386144.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_location.rename(columns={'location': 'label'}, inplace=True)\n",
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_3316/3099386144.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleanliness.rename(columns={'cleanliness': 'label'}, inplace=True)\n",
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_3316/3099386144.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_service.rename(columns={'service': 'label'}, inplace=True)\n",
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_3316/3099386144.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_facilities.rename(columns={'facilities': 'label'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#df_value_train, df_comfort_train, df_location_train, df_cleanliness_train, df_service_train ,df_facilities_train = split_df(df_train)\n",
    "#df_value_test, df_comfort_test, df_location_test, df_cleanliness_test, df_service_test, df_facilities_test = split_df(df_test)\n",
    "df_value, df_comfort, df_location, df_cleanliness, df_service ,df_facilities = split_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbc20206-24d9-43f4-96c9-ab61f326eec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filtered_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>價格(Na),合理(VH),舒適(VH),房間(Nc),老闆娘(Na),人(Na),好(VH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>內部(Ncd),房間(Nc),乾淨(VH),場地(Na),團體(Na),使用(VC),覺得(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>房間(Nc),小(VH),美中不足(VH),乾(VH),濕(VH),分離(VHC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>房子(Na),設計(VC),棒(VH),房間(Nc),採光(Na),好(VH),大廳(Nc)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Cp值(FW),高(VH),乾淨(VH),舒適(VH),空間(Na),大樓(Na),下(Nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>1.0</td>\n",
       "      <td>港式(Na),飲茶(VA),餐廳(Nc),口味(Na),棒(VH),環境(Na),乾淨(VH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>場地(Na),氣派(Na),丁香魚(Na),酥脆(VH),服務(VC),親切(VH),蠟味(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1.0</td>\n",
       "      <td>交通(Na),方便(VH),地下室(Nc),停車場(Nc),良好(VH),菜色(Na),好(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>地點(Na),佳(VH),離(P),逢甲(Nb),夜市(Nc),老闆娘(Na),親切(VH)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>0.0</td>\n",
       "      <td>房間(Nc),乾淨(VH),價格(Na),公道(VH),老闆娘(Na),親切(VH),逢甲(...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                      filtered_word\n",
       "0       0.0  價格(Na),合理(VH),舒適(VH),房間(Nc),老闆娘(Na),人(Na),好(VH...\n",
       "1       1.0  內部(Ncd),房間(Nc),乾淨(VH),場地(Na),團體(Na),使用(VC),覺得(...\n",
       "2       0.0          房間(Nc),小(VH),美中不足(VH),乾(VH),濕(VH),分離(VHC)\n",
       "3       1.0  房子(Na),設計(VC),棒(VH),房間(Nc),採光(Na),好(VH),大廳(Nc)...\n",
       "4       0.0  Cp值(FW),高(VH),乾淨(VH),舒適(VH),空間(Na),大樓(Na),下(Nc...\n",
       "...     ...                                                ...\n",
       "1267    1.0  港式(Na),飲茶(VA),餐廳(Nc),口味(Na),棒(VH),環境(Na),乾淨(VH...\n",
       "1268    0.0  場地(Na),氣派(Na),丁香魚(Na),酥脆(VH),服務(VC),親切(VH),蠟味(...\n",
       "1269    1.0  交通(Na),方便(VH),地下室(Nc),停車場(Nc),良好(VH),菜色(Na),好(...\n",
       "1270    0.0  地點(Na),佳(VH),離(P),逢甲(Nb),夜市(Nc),老闆娘(Na),親切(VH)...\n",
       "1271    0.0  房間(Nc),乾淨(VH),價格(Na),公道(VH),老闆娘(Na),親切(VH),逢甲(...\n",
       "\n",
       "[1272 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ec4bf-a42d-406c-a15e-54431ef328fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 清理資料(移除詞性標註的文字)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cb95288-72e7-4508-aa53-1684ff8a63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_N_comma(sentence):\n",
    "    # 把後面(N..)(V..)(F..)拿掉\n",
    "    sentence = str(sentence)\n",
    "    pattern = re.compile(r\"\\([N,V,F,P].*?\\)\") #移除詞性標示\n",
    "    sentence = re.sub(pattern, '', sentence)\n",
    "    pattern = re.compile(r\",\") #將逗號替換為空格\n",
    "    sentence = re.sub(pattern, ' ', sentence)\n",
    "    return sentence\n",
    "pd.options.mode.chained_assignment = None  # 忽略警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f29d4e13-b275-406a-96c1-fd46f70772bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練集\n",
    "df_facilities['filtered_word'] = df_facilities.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96657345-dcdf-40d4-b09b-2904f3ea0281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1272, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filtered_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>價格 合理 舒適 房間 老闆娘 人 好 做 早餐 旅客 重點 早餐 吃到飽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>內部 房間 乾淨 場地 團體 使用 覺得 棒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>房間 小 美中不足 乾 濕 分離</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>房子 設計 棒 房間 採光 好 大廳 挑高 氣派 房價 合理 台東 住 民宿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Cp值 高 乾淨 舒適 空間 大樓 下 免費 吐司 咖啡 老闆 回復 速度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>1.0</td>\n",
       "      <td>港式 飲茶 餐廳 口味 棒 環境 乾淨 機車 汽車 停車位 位於 高鐵 附近 適合 宴客</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>場地 氣派 丁香魚 酥脆 服務 親切 蠟味 蘿蔔糕 份量 一些 好 牛肉粥 好吃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1.0</td>\n",
       "      <td>交通 方便 地下室 停車場 良好 菜色 好 空間 設計好 說 一流 飯店</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>地點 佳 離 逢甲 夜市 老闆娘 親切 服務 房間 舒適 浴室 乾淨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>0.0</td>\n",
       "      <td>房間 乾淨 價格 公道 老闆娘 親切 逢甲 推 民宿 推</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                 filtered_word\n",
       "0       0.0         價格 合理 舒適 房間 老闆娘 人 好 做 早餐 旅客 重點 早餐 吃到飽\n",
       "1       1.0                        內部 房間 乾淨 場地 團體 使用 覺得 棒\n",
       "2       0.0                              房間 小 美中不足 乾 濕 分離\n",
       "3       1.0        房子 設計 棒 房間 採光 好 大廳 挑高 氣派 房價 合理 台東 住 民宿\n",
       "4       0.0         Cp值 高 乾淨 舒適 空間 大樓 下 免費 吐司 咖啡 老闆 回復 速度\n",
       "...     ...                                           ...\n",
       "1267    1.0  港式 飲茶 餐廳 口味 棒 環境 乾淨 機車 汽車 停車位 位於 高鐵 附近 適合 宴客\n",
       "1268    0.0      場地 氣派 丁香魚 酥脆 服務 親切 蠟味 蘿蔔糕 份量 一些 好 牛肉粥 好吃\n",
       "1269    1.0          交通 方便 地下室 停車場 良好 菜色 好 空間 設計好 說 一流 飯店\n",
       "1270    0.0            地點 佳 離 逢甲 夜市 老闆娘 親切 服務 房間 舒適 浴室 乾淨\n",
       "1271    0.0                  房間 乾淨 價格 公道 老闆娘 親切 逢甲 推 民宿 推\n",
       "\n",
       "[1272 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_facilities.shape)\n",
    "df_facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b21127-7864-4ea5-bbc6-872b5ce25697",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 模型架構"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f5dea5-298a-4819-8ac5-520b79eb20c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 套件引用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f68cb11-c4ef-4366-9a3f-9af34c9dd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import package\n",
    "#轉向量用\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pickle #儲存模型用\n",
    "from sklearn.model_selection import train_test_split\n",
    "#類別採樣\n",
    "import imblearn.over_sampling as over_sampling\n",
    "import imblearn.under_sampling as under_sampling\n",
    "import imblearn.combine as combine\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "\n",
    "\n",
    "#模型\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "#模型效能表現\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bca335-929e-46d6-b8e6-447621d41d8c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 顯示訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad34b64-c7c9-4cce-8b62-0a266a165a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(y_test, pre):\n",
    "    #混淆矩陣\n",
    "    confusion = metrics.confusion_matrix(y_test, pre)\n",
    "    TP = confusion[1,1]\n",
    "    TN = confusion[0,0]\n",
    "    FP = confusion[0,1]\n",
    "    FN = confusion[1,0]\n",
    "    print(\"TP:\",TP)\n",
    "    print(\"TN:\",TN)\n",
    "    print(\"FP:\",FP)\n",
    "    print(\"FN:\",FN)\n",
    "    #Accuracy\n",
    "    accuracy = (TP+TN)/float(TP+TN+FN+FP)\n",
    "    print(\"Accuracy：\", accuracy)\n",
    "    #Sensitivity(Recall)\n",
    "    recall = TP/float(TP+FN)\n",
    "    print(\"Recall：\", recall)\n",
    "    #Specificity\n",
    "    specificity = TN/float(TN+FP)\n",
    "    print(\"Specificity：\", specificity)\n",
    "    #Precision\n",
    "    precision = TP/float(TP+FP)\n",
    "    print(\"Precision：\", precision)\n",
    "    #f1-score\n",
    "    f1_score = ((2*precision*recall)/(precision+recall))\n",
    "    print(\"f1_score：\", f1_score)\n",
    "    #AUC\n",
    "    print(\"AUC：\", metrics.roc_auc_score(y_test, pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c37f894c-b179-4711-92b8-6e86c3c15e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>filtered_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>價格 合理 舒適 房間 老闆娘 人 好 做 早餐 旅客 重點 早餐 吃到飽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>內部 房間 乾淨 場地 團體 使用 覺得 棒</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>房間 小 美中不足 乾 濕 分離</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>房子 設計 棒 房間 採光 好 大廳 挑高 氣派 房價 合理 台東 住 民宿</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Cp值 高 乾淨 舒適 空間 大樓 下 免費 吐司 咖啡 老闆 回復 速度</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>1.0</td>\n",
       "      <td>港式 飲茶 餐廳 口味 棒 環境 乾淨 機車 汽車 停車位 位於 高鐵 附近 適合 宴客</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0.0</td>\n",
       "      <td>場地 氣派 丁香魚 酥脆 服務 親切 蠟味 蘿蔔糕 份量 一些 好 牛肉粥 好吃</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>1.0</td>\n",
       "      <td>交通 方便 地下室 停車場 良好 菜色 好 空間 設計好 說 一流 飯店</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0.0</td>\n",
       "      <td>地點 佳 離 逢甲 夜市 老闆娘 親切 服務 房間 舒適 浴室 乾淨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>0.0</td>\n",
       "      <td>房間 乾淨 價格 公道 老闆娘 親切 逢甲 推 民宿 推</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                 filtered_word\n",
       "0       0.0         價格 合理 舒適 房間 老闆娘 人 好 做 早餐 旅客 重點 早餐 吃到飽\n",
       "1       1.0                        內部 房間 乾淨 場地 團體 使用 覺得 棒\n",
       "2       0.0                              房間 小 美中不足 乾 濕 分離\n",
       "3       1.0        房子 設計 棒 房間 採光 好 大廳 挑高 氣派 房價 合理 台東 住 民宿\n",
       "4       0.0         Cp值 高 乾淨 舒適 空間 大樓 下 免費 吐司 咖啡 老闆 回復 速度\n",
       "...     ...                                           ...\n",
       "1267    1.0  港式 飲茶 餐廳 口味 棒 環境 乾淨 機車 汽車 停車位 位於 高鐵 附近 適合 宴客\n",
       "1268    0.0      場地 氣派 丁香魚 酥脆 服務 親切 蠟味 蘿蔔糕 份量 一些 好 牛肉粥 好吃\n",
       "1269    1.0          交通 方便 地下室 停車場 良好 菜色 好 空間 設計好 說 一流 飯店\n",
       "1270    0.0            地點 佳 離 逢甲 夜市 老闆娘 親切 服務 房間 舒適 浴室 乾淨\n",
       "1271    0.0                  房間 乾淨 價格 公道 老闆娘 親切 逢甲 推 民宿 推\n",
       "\n",
       "[1272 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8636ec-e7a7-433b-a876-342010132df4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 切分訓練、測試數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce72c298-701c-4007-9cff-6555b3c30490",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def split_label(df,seed):\n",
    "    X = df.filtered_word.tolist()\n",
    "    y = df.label\n",
    "    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=1/3,random_state=seed)\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "936320a6-0c24-47de-8acb-13d32d05d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1,X_test_1,y_train_1,y_test_1 = split_label(df_facilities,1)\n",
    "X_train_2,X_test_2,y_train_2,y_test_2 = split_label(df_facilities,2)\n",
    "X_train_3,X_test_3,y_train_3,y_test_3 = split_label(df_facilities,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25654090-f10c-4123-8506-d80314fa1c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    638\n",
      "1.0    210\n",
      "Name: label, dtype: int64\n",
      "0.0    639\n",
      "1.0    209\n",
      "Name: label, dtype: int64\n",
      "0.0    652\n",
      "1.0    196\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "s1 = pd.Series(y_train_1)\n",
    "freq1 = s1.value_counts() \n",
    "print(freq1) \n",
    "s2 = pd.Series(y_train_2)\n",
    "freq2 = s2.value_counts() \n",
    "print(freq2) \n",
    "s3 = pd.Series(y_train_3)\n",
    "freq3 = s3.value_counts() \n",
    "print(freq3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fee28-9feb-4801-bb55-f2e537ac12d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 模型設計"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c74e39-1bbe-4c80-ad06-0e3074ae7329",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### (1) baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4effeedd-3a62-4931-a963-d0cdae920390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model(X_train,X_test,y_train,y_test):\n",
    "    print(\"SVM baseline\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(max_df=0.8,min_df=5,dtype=np.float32), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "582d7fde-ba62-4a98-9725-9d770485c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LR_model(X_train,X_test,y_train,y_test):\n",
    "    print(\"LR baseline\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(max_df=0.8,min_df=5,dtype=np.float32), LogisticRegression(random_state=0))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80043705-9df6-43de-a64a-bfa8f2ea4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF_model(X_train,X_test,y_train,y_test):\n",
    "    print(\"RF baseline\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(max_df=0.8,min_df=5,dtype=np.float32), RandomForestClassifier(max_depth=2, random_state=0))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef4c1d09-9c26-489a-b946-f3eb16cdca9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model(X_train,X_test,y_train,y_test):\n",
    "    print(\"AdaBoost_model\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), AdaBoostClassifier(n_estimators=200))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd242fc-ed52-47a3-8e8e-950263def92b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### (2)執行採樣 => 解決類別不平衡 (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de9840cc-0b35-41a1-87fa-b57132a13672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model2(X_train,X_test,y_train,y_test):\n",
    "    print(\"ADASYN\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.ADASYN(), svm.SVC(kernel='linear'))\n",
    "    print(model)\n",
    "    # Get the names of each feature\n",
    "    model.fit(X_train, y_train)\n",
    "    feature_names = model.named_steps[\"tfidfvectorizer\"].get_feature_names()\n",
    "    print(feature_names)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4eda9758-34df-4676-ae93-3fb118fda294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()), ('adasyn', ADASYN()),\n",
      "                ('svc', SVC(kernel='linear'))])\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3316/1258744174.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mSVM_model2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3316/3993109840.py\u001b[0m in \u001b[0;36mSVM_model2\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# Get the names of each feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tfidfvectorizer\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mget_feature_names\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1293\u001b[0m         \"\"\"\n\u001b[0;32m   1294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m         return [t for t, i in sorted(self.vocabulary_.items(),\n",
      "\u001b[1;32m~\\anaconda3\\envs\\NLP\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Vocabulary not fitted or provided\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "SVM_model2(X_train_1,X_test_1,y_train_1,y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b56f9250-4755-4aef-acbf-0a0e24dfefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model3(X_train,X_test,y_train,y_test):\n",
    "    print(\"SMOTE\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.SMOTE(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17634123-3d47-49b6-aecd-e949c4226cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model4(X_train,X_test,y_train,y_test):\n",
    "    print(\"RandomOverSampler\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.RandomOverSampler(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0c4654d-5f7a-474a-adb0-e151c3eaffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model5(X_train,X_test,y_train,y_test):\n",
    "    print(\"RandomUnderSampler\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), under_sampling.RandomUnderSampler(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259a3f1f-a2b0-444d-8c27-09e25477c011",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### (3)執行採樣 => 解決類別不平衡 (Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ccdebd6-b168-4328-b945-d6a3f5bb6727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model2(X_train,X_test,y_train,y_test):\n",
    "    print(\"ADASYN\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.ADASYN(), AdaBoostClassifier(n_estimators=200))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c73e184-3030-4ca2-be1e-62bd33ccfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model3(X_train,X_test,y_train,y_test):\n",
    "    print(\"SMOTE\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.SMOTE(), AdaBoostClassifier(n_estimators=200))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1284a043-f531-4f0c-b810-79505df5608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model4(X_train,X_test,y_train,y_test):\n",
    "    print(\"RandomOverSampler\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.RandomOverSampler(), AdaBoostClassifier(n_estimators=200))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bebfbf5-6b8f-4a97-b1b7-c7e664be046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model5(X_train,X_test,y_train,y_test):\n",
    "    print(\"RandomUnderSampler\")\n",
    "    #切分數據集\n",
    "    #X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), under_sampling.RandomUnderSampler(), AdaBoostClassifier(n_estimators=200))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d93f4-b593-4079-a7ee-50106af14326",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 模型訓練&結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87038cb-fcf0-487b-be81-3b9ed8ac340d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 資料集1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307939ac-c4f2-4bfb-a2c3-4bd0022e34c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a8b3b39-db3f-4b2f-b9b1-f160fc1c2338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline\n",
      "TP: 38\n",
      "TN: 316\n",
      "FP: 8\n",
      "FN: 62\n",
      "Accuracy： 0.8349056603773585\n",
      "Recall： 0.38\n",
      "Specificity： 0.9753086419753086\n",
      "Precision： 0.8260869565217391\n",
      "f1_score： 0.5205479452054794\n",
      "AUC： 0.6776543209876542\n",
      "\n",
      "\n",
      "LR baseline\n",
      "TP: 18\n",
      "TN: 321\n",
      "FP: 3\n",
      "FN: 82\n",
      "Accuracy： 0.7995283018867925\n",
      "Recall： 0.18\n",
      "Specificity： 0.9907407407407407\n",
      "Precision： 0.8571428571428571\n",
      "f1_score： 0.2975206611570248\n",
      "AUC： 0.5853703703703703\n",
      "\n",
      "\n",
      "RF baseline\n",
      "TP: 0\n",
      "TN: 324\n",
      "FP: 0\n",
      "FN: 100\n",
      "Accuracy： 0.7641509433962265\n",
      "Recall： 0.0\n",
      "Specificity： 1.0\n",
      "Precision： nan\n",
      "f1_score： nan\n",
      "AUC： 0.5\n",
      "\n",
      "\n",
      "AdaBoost_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_3316/3777238089.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  precision = TP/float(TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 53\n",
      "TN: 294\n",
      "FP: 30\n",
      "FN: 47\n",
      "Accuracy： 0.8183962264150944\n",
      "Recall： 0.53\n",
      "Specificity： 0.9074074074074074\n",
      "Precision： 0.6385542168674698\n",
      "f1_score： 0.5792349726775956\n",
      "AUC： 0.7187037037037037\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "LR_model(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "RF_model(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "AdaBoost_model(X_train_1,X_test_1,y_train_1,y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f57e29b-b5da-4c19-bd5f-66566b2866b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8927158e-6bb9-4229-baa0-9375efea894d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 61\n",
      "TN: 294\n",
      "FP: 30\n",
      "FN: 39\n",
      "Accuracy： 0.8372641509433962\n",
      "Recall： 0.61\n",
      "Specificity： 0.9074074074074074\n",
      "Precision： 0.6703296703296703\n",
      "f1_score： 0.6387434554973822\n",
      "AUC： 0.7587037037037038\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 59\n",
      "TN: 297\n",
      "FP: 27\n",
      "FN: 41\n",
      "Accuracy： 0.839622641509434\n",
      "Recall： 0.59\n",
      "Specificity： 0.9166666666666666\n",
      "Precision： 0.686046511627907\n",
      "f1_score： 0.6344086021505376\n",
      "AUC： 0.7533333333333332\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 59\n",
      "TN: 299\n",
      "FP: 25\n",
      "FN: 41\n",
      "Accuracy： 0.8443396226415094\n",
      "Recall： 0.59\n",
      "Specificity： 0.9228395061728395\n",
      "Precision： 0.7023809523809523\n",
      "f1_score： 0.6413043478260868\n",
      "AUC： 0.7564197530864197\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 76\n",
      "TN: 236\n",
      "FP: 88\n",
      "FN: 24\n",
      "Accuracy： 0.7358490566037735\n",
      "Recall： 0.76\n",
      "Specificity： 0.7283950617283951\n",
      "Precision： 0.4634146341463415\n",
      "f1_score： 0.5757575757575758\n",
      "AUC： 0.7441975308641976\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model2(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "SVM_model3(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "SVM_model4(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "SVM_model5(X_train_1,X_test_1,y_train_1,y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2104f3fb-c135-4b1c-a4e9-f2523310eb9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49c81a34-8472-4d71-bbef-d69983019057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 56\n",
      "TN: 292\n",
      "FP: 32\n",
      "FN: 44\n",
      "Accuracy： 0.8207547169811321\n",
      "Recall： 0.56\n",
      "Specificity： 0.9012345679012346\n",
      "Precision： 0.6363636363636364\n",
      "f1_score： 0.5957446808510639\n",
      "AUC： 0.7306172839506173\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 58\n",
      "TN: 289\n",
      "FP: 35\n",
      "FN: 42\n",
      "Accuracy： 0.8183962264150944\n",
      "Recall： 0.58\n",
      "Specificity： 0.8919753086419753\n",
      "Precision： 0.6236559139784946\n",
      "f1_score： 0.6010362694300518\n",
      "AUC： 0.7359876543209876\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 55\n",
      "TN: 290\n",
      "FP: 34\n",
      "FN: 45\n",
      "Accuracy： 0.8136792452830188\n",
      "Recall： 0.55\n",
      "Specificity： 0.8950617283950617\n",
      "Precision： 0.6179775280898876\n",
      "f1_score： 0.582010582010582\n",
      "AUC： 0.7225308641975309\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 66\n",
      "TN: 197\n",
      "FP: 127\n",
      "FN: 34\n",
      "Accuracy： 0.6202830188679245\n",
      "Recall： 0.66\n",
      "Specificity： 0.6080246913580247\n",
      "Precision： 0.34196891191709844\n",
      "f1_score： 0.4505119453924915\n",
      "AUC： 0.6340123456790124\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model2(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "AdaBoost_model3(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "AdaBoost_model4(X_train_1,X_test_1,y_train_1,y_test_1)\n",
    "AdaBoost_model5(X_train_1,X_test_1,y_train_1,y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7cd266-8e91-4db7-97ca-3ceca34d9271",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 資料集2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8465954-51b1-4f56-9650-9670379c1b3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5165c90-95d3-4716-9efa-1a87bb69310a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline\n",
      "TP: 28\n",
      "TN: 316\n",
      "FP: 7\n",
      "FN: 73\n",
      "Accuracy： 0.8113207547169812\n",
      "Recall： 0.27722772277227725\n",
      "Specificity： 0.978328173374613\n",
      "Precision： 0.8\n",
      "f1_score： 0.411764705882353\n",
      "AUC： 0.6277779480734451\n",
      "\n",
      "\n",
      "LR baseline\n",
      "TP: 17\n",
      "TN: 320\n",
      "FP: 3\n",
      "FN: 84\n",
      "Accuracy： 0.7948113207547169\n",
      "Recall： 0.16831683168316833\n",
      "Specificity： 0.9907120743034056\n",
      "Precision： 0.85\n",
      "f1_score： 0.2809917355371901\n",
      "AUC： 0.579514452993287\n",
      "\n",
      "\n",
      "RF baseline\n",
      "TP: 0\n",
      "TN: 323\n",
      "FP: 0\n",
      "FN: 101\n",
      "Accuracy： 0.7617924528301887\n",
      "Recall： 0.0\n",
      "Specificity： 1.0\n",
      "Precision： nan\n",
      "f1_score： nan\n",
      "AUC： 0.5\n",
      "\n",
      "\n",
      "AdaBoost_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_3316/3777238089.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  precision = TP/float(TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 56\n",
      "TN: 289\n",
      "FP: 34\n",
      "FN: 45\n",
      "Accuracy： 0.8136792452830188\n",
      "Recall： 0.5544554455445545\n",
      "Specificity： 0.8947368421052632\n",
      "Precision： 0.6222222222222222\n",
      "f1_score： 0.5863874345549739\n",
      "AUC： 0.7245961438249089\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "LR_model(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "RF_model(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "AdaBoost_model(X_train_2,X_test_2,y_train_2,y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71898e-545d-4724-90ee-4c55ed7cd8bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17549184-0a46-42ae-9291-d1d6b9f1f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 57\n",
      "TN: 289\n",
      "FP: 34\n",
      "FN: 44\n",
      "Accuracy： 0.8160377358490566\n",
      "Recall： 0.5643564356435643\n",
      "Specificity： 0.8947368421052632\n",
      "Precision： 0.6263736263736264\n",
      "f1_score： 0.5937499999999999\n",
      "AUC： 0.7295466388744138\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 58\n",
      "TN: 291\n",
      "FP: 32\n",
      "FN: 43\n",
      "Accuracy： 0.8231132075471698\n",
      "Recall： 0.5742574257425742\n",
      "Specificity： 0.9009287925696594\n",
      "Precision： 0.6444444444444445\n",
      "f1_score： 0.6073298429319371\n",
      "AUC： 0.7375931091561169\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 53\n",
      "TN: 293\n",
      "FP: 30\n",
      "FN: 48\n",
      "Accuracy： 0.8160377358490566\n",
      "Recall： 0.5247524752475248\n",
      "Specificity： 0.9071207430340558\n",
      "Precision： 0.6385542168674698\n",
      "f1_score： 0.5760869565217391\n",
      "AUC： 0.7159366091407903\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 72\n",
      "TN: 234\n",
      "FP: 89\n",
      "FN: 29\n",
      "Accuracy： 0.7216981132075472\n",
      "Recall： 0.7128712871287128\n",
      "Specificity： 0.7244582043343654\n",
      "Precision： 0.4472049689440994\n",
      "f1_score： 0.549618320610687\n",
      "AUC： 0.718664745731539\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model2(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "SVM_model3(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "SVM_model4(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "SVM_model5(X_train_2,X_test_2,y_train_2,y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991a1084-02ce-4dc5-85fd-3c65d6d8265c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f696397-9819-49b2-99b8-58a2c9ccc5fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 54\n",
      "TN: 294\n",
      "FP: 29\n",
      "FN: 47\n",
      "Accuracy： 0.8207547169811321\n",
      "Recall： 0.5346534653465347\n",
      "Specificity： 0.9102167182662538\n",
      "Precision： 0.6506024096385542\n",
      "f1_score： 0.5869565217391304\n",
      "AUC： 0.7224350918063942\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 52\n",
      "TN: 301\n",
      "FP: 22\n",
      "FN: 49\n",
      "Accuracy： 0.8325471698113207\n",
      "Recall： 0.5148514851485149\n",
      "Specificity： 0.9318885448916409\n",
      "Precision： 0.7027027027027027\n",
      "f1_score： 0.5942857142857144\n",
      "AUC： 0.7233700150200779\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 57\n",
      "TN: 287\n",
      "FP: 36\n",
      "FN: 44\n",
      "Accuracy： 0.8113207547169812\n",
      "Recall： 0.5643564356435643\n",
      "Specificity： 0.8885448916408669\n",
      "Precision： 0.6129032258064516\n",
      "f1_score： 0.5876288659793815\n",
      "AUC： 0.7264506636422157\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 65\n",
      "TN: 255\n",
      "FP: 68\n",
      "FN: 36\n",
      "Accuracy： 0.7547169811320755\n",
      "Recall： 0.6435643564356436\n",
      "Specificity： 0.7894736842105263\n",
      "Precision： 0.48872180451127817\n",
      "f1_score： 0.5555555555555556\n",
      "AUC： 0.716519020323085\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model2(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "AdaBoost_model3(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "AdaBoost_model4(X_train_2,X_test_2,y_train_2,y_test_2)\n",
    "AdaBoost_model5(X_train_2,X_test_2,y_train_2,y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a73c197-ac2c-42dd-808f-fd8fc66ba2e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 資料集3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d18ad43-e437-40b1-97cf-4341df882d50",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a8c07-7bd3-4541-8096-f7e3d59048b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline\n",
      "TP: 37\n",
      "TN: 305\n",
      "FP: 5\n",
      "FN: 77\n",
      "Accuracy： 0.8066037735849056\n",
      "Recall： 0.32456140350877194\n",
      "Specificity： 0.9838709677419355\n",
      "Precision： 0.8809523809523809\n",
      "f1_score： 0.4743589743589744\n",
      "AUC： 0.6542161856253537\n",
      "\n",
      "\n",
      "LR baseline\n",
      "TP: 24\n",
      "TN: 306\n",
      "FP: 4\n",
      "FN: 90\n",
      "Accuracy： 0.7783018867924528\n",
      "Recall： 0.21052631578947367\n",
      "Specificity： 0.9870967741935484\n",
      "Precision： 0.8571428571428571\n",
      "f1_score： 0.33802816901408456\n",
      "AUC： 0.598811544991511\n",
      "\n",
      "\n",
      "RF baseline\n",
      "TP: 0\n",
      "TN: 310\n",
      "FP: 0\n",
      "FN: 114\n",
      "Accuracy： 0.7311320754716981\n",
      "Recall： 0.0\n",
      "Specificity： 1.0\n",
      "Precision： nan\n",
      "f1_score： nan\n",
      "AUC： 0.5\n",
      "\n",
      "\n",
      "AdaBoost_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_3316/3777238089.py:22: RuntimeWarning: invalid value encountered in true_divide\n",
      "  precision = TP/float(TP+FP)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 59\n",
      "TN: 277\n",
      "FP: 33\n",
      "FN: 55\n",
      "Accuracy： 0.7924528301886793\n",
      "Recall： 0.5175438596491229\n",
      "Specificity： 0.8935483870967742\n",
      "Precision： 0.6413043478260869\n",
      "f1_score： 0.5728155339805826\n",
      "AUC： 0.7055461233729485\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "LR_model(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "RF_model(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "AdaBoost_model(X_train_3,X_test_3,y_train_3,y_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e9a68-245f-4986-b075-297e19ec9c4f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f4234-e09b-4844-aada-ebfb0d99164b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 65\n",
      "TN: 286\n",
      "FP: 24\n",
      "FN: 49\n",
      "Accuracy： 0.8278301886792453\n",
      "Recall： 0.5701754385964912\n",
      "Specificity： 0.9225806451612903\n",
      "Precision： 0.7303370786516854\n",
      "f1_score： 0.6403940886699507\n",
      "AUC： 0.7463780418788908\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 60\n",
      "TN: 290\n",
      "FP: 20\n",
      "FN: 54\n",
      "Accuracy： 0.8254716981132075\n",
      "Recall： 0.5263157894736842\n",
      "Specificity： 0.9354838709677419\n",
      "Precision： 0.75\n",
      "f1_score： 0.6185567010309279\n",
      "AUC： 0.7308998302207131\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 60\n",
      "TN: 292\n",
      "FP: 18\n",
      "FN: 54\n",
      "Accuracy： 0.8301886792452831\n",
      "Recall： 0.5263157894736842\n",
      "Specificity： 0.9419354838709677\n",
      "Precision： 0.7692307692307693\n",
      "f1_score： 0.625\n",
      "AUC： 0.7341256366723259\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 80\n",
      "TN: 228\n",
      "FP: 82\n",
      "FN: 34\n",
      "Accuracy： 0.7264150943396226\n",
      "Recall： 0.7017543859649122\n",
      "Specificity： 0.7354838709677419\n",
      "Precision： 0.49382716049382713\n",
      "f1_score： 0.5797101449275363\n",
      "AUC： 0.718619128466327\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SVM_model2(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "SVM_model3(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "SVM_model4(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "SVM_model5(X_train_3,X_test_3,y_train_3,y_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a324278d-a492-448e-8f16-8b40c028da72",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 處理類別不平衡(Adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f492523-c149-4374-b132-e706f8a97e51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN\n",
      "TP: 63\n",
      "TN: 285\n",
      "FP: 25\n",
      "FN: 51\n",
      "Accuracy： 0.8207547169811321\n",
      "Recall： 0.5526315789473685\n",
      "Specificity： 0.9193548387096774\n",
      "Precision： 0.7159090909090909\n",
      "f1_score： 0.6237623762376238\n",
      "AUC： 0.7359932088285229\n",
      "\n",
      "\n",
      "SMOTE\n",
      "TP: 59\n",
      "TN: 280\n",
      "FP: 30\n",
      "FN: 55\n",
      "Accuracy： 0.7995283018867925\n",
      "Recall： 0.5175438596491229\n",
      "Specificity： 0.9032258064516129\n",
      "Precision： 0.6629213483146067\n",
      "f1_score： 0.5812807881773399\n",
      "AUC： 0.7103848330503679\n",
      "\n",
      "\n",
      "RandomOverSampler\n",
      "TP: 59\n",
      "TN: 281\n",
      "FP: 29\n",
      "FN: 55\n",
      "Accuracy： 0.8018867924528302\n",
      "Recall： 0.5175438596491229\n",
      "Specificity： 0.9064516129032258\n",
      "Precision： 0.6704545454545454\n",
      "f1_score： 0.5841584158415842\n",
      "AUC： 0.7119977362761745\n",
      "\n",
      "\n",
      "RandomUnderSampler\n",
      "TP: 78\n",
      "TN: 230\n",
      "FP: 80\n",
      "FN: 36\n",
      "Accuracy： 0.7264150943396226\n",
      "Recall： 0.6842105263157895\n",
      "Specificity： 0.7419354838709677\n",
      "Precision： 0.4936708860759494\n",
      "f1_score： 0.5735294117647058\n",
      "AUC： 0.7130730050933787\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AdaBoost_model2(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "AdaBoost_model3(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "AdaBoost_model4(X_train_3,X_test_3,y_train_3,y_test_3)\n",
    "AdaBoost_model5(X_train_3,X_test_3,y_train_3,y_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c0668-fdc5-4c35-9400-f082ac358fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e639f1c3-bcb5-462c-acc2-c8066001055d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191233ff-81b0-4f49-9730-8e2114a7c2c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
