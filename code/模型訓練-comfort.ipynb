{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608f9531-d9c0-47a4-bf7b-fcfe91992f8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 幾種思路"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae267fd-f953-442a-88cc-e2bfb9aff87d",
   "metadata": {},
   "source": [
    "思路1：TF-IDF + 機器學習分類器\n",
    "直接使用TF-IDF對文本提取特徵，並使用分類器進行分類。在分類器的選擇上，可以使用SVM、LR、或者XGBoost。\n",
    "\n",
    "思路2：FastText\n",
    "FastText是入門款的詞向量，利用Facebook提供的FastText工具，可以快速構建出分類器。\n",
    "\n",
    "思路3：WordVec + 深度學習分類器\n",
    "WordVec是進階款的詞向量，並通過構建深度學習分類完成分類。深度學習分類的網絡結構可以選擇TextCNN、TextRNN或者BiLSTM。\n",
    "\n",
    "思路4：Bert詞向量\n",
    "Bert是高配款的詞向量，具有強大的建模學習能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10abf616-467b-4883-8210-339068693e2b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 獲取6種模型的資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f1556b9-10a8-4230-910e-2e0851184854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "path = '../data/0407/review_data(seg+pos+stopwords)_train_n+v+f+p.csv'\n",
    "df_train = pd.read_csv(path)\n",
    "path = '../data/0407/review_data(seg+pos+stopwords)_test_n+v+f+p.csv'\n",
    "df_test = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03134552-b205-4ba6-8b30-49d1b63f6e8d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 檢查重複值、空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cf01f08b-66b4-48dc-b539-f963be31ec24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [reviews, value, comfort, location, cleanliness, service, facilities, ws_pos_reviews, filtered, filtered_word]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [reviews, value, comfort, location, cleanliness, service, facilities, ws_pos_reviews, filtered, filtered_word]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#印出重複資料\n",
    "print(df_test[df_test.duplicated()])\n",
    "print(df_train[df_train.duplicated()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1fcd3385-74b6-4e0e-8a68-48f139e3161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#移除重複值\n",
    "#df = df.drop_duplicates()\n",
    "#print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "57541fcf-3859-4b9d-a6af-68c3a1b7a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#印出空值資料\n",
    "#df_train[df_train.isnull().T.any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef2dd09-a1d4-408b-af22-a11cdd6829a9",
   "metadata": {},
   "source": [
    "### 切分為6個資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e466b400-44e6-442f-914f-148dc9f2cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    df_value = df[['value','filtered_word']]\n",
    "    df_value.rename(columns={'value': 'label'}, inplace=True)\n",
    "    df_comfort = df[['comfort','filtered_word']]\n",
    "    df_comfort.rename(columns={'comfort': 'label'}, inplace=True)\n",
    "    df_location = df[['location','filtered_word']]\n",
    "    df_location.rename(columns={'location': 'label'}, inplace=True)\n",
    "    df_cleanliness = df[['cleanliness','filtered_word']]\n",
    "    df_cleanliness.rename(columns={'cleanliness': 'label'}, inplace=True)\n",
    "    df_service = df[['service','filtered_word']]\n",
    "    df_service.rename(columns={'service': 'label'}, inplace=True)\n",
    "    df_facilities = df[['facilities','filtered_word']]\n",
    "    df_facilities.rename(columns={'facilities': 'label'}, inplace=True)\n",
    "    return df_value, df_comfort, df_location, df_cleanliness, df_service, df_facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f74887e2-a787-4bba-af45-b6824ebbf6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_value_train, df_comfort_train, df_location_train, df_cleanliness_train, df_service_train ,df_facilities_train = split_df(df_train)\n",
    "df_value_test, df_comfort_test, df_location_test, df_cleanliness_test, df_service_test, df_facilities_test = split_df(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ec4bf-a42d-406c-a15e-54431ef328fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 清理資料(移除詞性標註的文字)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cb95288-72e7-4508-aa53-1684ff8a63e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_N_comma(sentence):\n",
    "    # 把後面(N..)(V..)(F..)拿掉\n",
    "    sentence = str(sentence)\n",
    "    pattern = re.compile(r\"\\([N,V,F,P].*?\\)\") #移除詞性標示\n",
    "    sentence = re.sub(pattern, '', sentence)\n",
    "    pattern = re.compile(r\",\") #將逗號替換為空格\n",
    "    sentence = re.sub(pattern, ' ', sentence)\n",
    "    return sentence\n",
    "pd.options.mode.chained_assignment = None  # 忽略警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f29d4e13-b275-406a-96c1-fd46f70772bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#訓練集\n",
    "df_value_train['filtered_word'] = df_value_train.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "df_comfort_train['filtered_word'] = df_comfort_train.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "df_location_train['filtered_word'] = df_location_train.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "df_cleanliness_train['filtered_word'] = df_cleanliness_train.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "df_service_train['filtered_word'] = df_service_train.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "df_facilities_train['filtered_word'] = df_facilities_train.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "#測試集\n",
    "df_value_test['filtered_word'] = df_value_test.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "df_comfort_test['filtered_word'] = df_comfort_test.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "df_location_test['filtered_word'] = df_location_test.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "df_cleanliness_test['filtered_word'] = df_cleanliness_test.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "df_service_test['filtered_word'] = df_service_test.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)\n",
    "df_facilities_test['filtered_word'] = df_facilities_test.apply(lambda x: remove_N_comma(x['filtered_word']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96657345-dcdf-40d4-b09b-2904f3ea0281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_value_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b21127-7864-4ea5-bbc6-872b5ce25697",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 模型架構"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f5dea5-298a-4819-8ac5-520b79eb20c2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 套件引用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f68cb11-c4ef-4366-9a3f-9af34c9dd711",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import package\n",
    "#轉向量用\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "import pickle #儲存模型用\n",
    "from sklearn.model_selection import train_test_split\n",
    "#類別採樣\n",
    "import imblearn.over_sampling as over_sampling\n",
    "import imblearn.under_sampling as under_sampling\n",
    "import imblearn.combine as combine\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "\n",
    "\n",
    "#模型\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "#模型效能表現\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bca335-929e-46d6-b8e6-447621d41d8c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 顯示訓練結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ad34b64-c7c9-4cce-8b62-0a266a165a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(y_test, pre):\n",
    "    #混淆矩陣\n",
    "    confusion = metrics.confusion_matrix(y_test, pre)\n",
    "    TP = confusion[1,1]\n",
    "    TN = confusion[0,0]\n",
    "    FP = confusion[0,1]\n",
    "    FN = confusion[1,0]\n",
    "    #Accuracy\n",
    "    accuracy = (TP+TN)/float(TP+TN+FN+FP)\n",
    "    print(\"Accuracy：\", accuracy)\n",
    "    #Sensitivity(Recall)\n",
    "    recall = TP/float(TP+FN)\n",
    "    print(\"Recall：\", recall)\n",
    "    #Specificity\n",
    "    specificity = TN/float(TN+FP)\n",
    "    print(\"Specificity：\", specificity)\n",
    "    #Precision\n",
    "    precision = TP/float(TP+FP)\n",
    "    print(\"Precision：\", precision)\n",
    "    #f1-score\n",
    "    f1_score = ((2*precision*recall)/(precision+recall))\n",
    "    print(\"f1_score：\", f1_score)\n",
    "    #AUC\n",
    "    print(\"AUC：\", metrics.roc_auc_score(y_test, pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8636ec-e7a7-433b-a876-342010132df4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 切分數據label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ce72c298-701c-4007-9cff-6555b3c30490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_label(df_train, df_test):\n",
    "    X_train = df_train.filtered_word.tolist()\n",
    "    y_train = df_train.label\n",
    "    X_test = df_test.filtered_word.tolist()\n",
    "    y_test = df_test.label\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0fee28-9feb-4801-bb55-f2e537ac12d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### SVM模型設計"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c74e39-1bbe-4c80-ad06-0e3074ae7329",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### (1) baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4effeedd-3a62-4931-a963-d0cdae920390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model(df_train, df_test):\n",
    "    print(\"SVM baseline\")\n",
    "    #切分數據集\n",
    "    X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(max_df=0.8,min_df=5,dtype=np.float32), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd242fc-ed52-47a3-8e8e-950263def92b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### (2)執行採樣 => 解決類別不平衡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "de9840cc-0b35-41a1-87fa-b57132a13672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model2(df_train, df_test):\n",
    "    print(\"ADASYN\")\n",
    "    #切分數據集\n",
    "    X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.ADASYN(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b56f9250-4755-4aef-acbf-0a0e24dfefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model3(df_train, df_test):\n",
    "    print(\"SMOTE\")\n",
    "    #切分數據集\n",
    "    X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.SMOTE(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17634123-3d47-49b6-aecd-e949c4226cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model4(df_train, df_test):\n",
    "    print(\"RandomOverSampler\")\n",
    "    #切分數據集\n",
    "    X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), over_sampling.RandomOverSampler(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e0c4654d-5f7a-474a-adb0-e151c3eaffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_model5(df_train, df_test):\n",
    "    print(\"RandomUnderSampler\")\n",
    "    #切分數據集\n",
    "    X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), under_sampling.RandomUnderSampler(), svm.SVC(kernel='linear'))\n",
    "    model.fit(X_train, y_train)\n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976bdddd-b3e0-41a8-a742-4007a6ed02ff",
   "metadata": {},
   "source": [
    "### Ensemble 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "87ecbae5-38b3-4f7d-931c-4200de83d82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaBoost_model(df_train, df_test):\n",
    "    print(\"AdaBoost_model\")\n",
    "    #切分數據集\n",
    "    X_train,y_train,X_test,y_test = split_label(df_train, df_test)\n",
    "    #模型架構\n",
    "    model = make_pipeline_imb(TfidfVectorizer(), AdaBoostClassifier(n_estimators=300, learning_rate=0.9))\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    #模型預測\n",
    "    pre = model.predict(X_test)\n",
    "    #麼行評估\n",
    "    classification_report(y_test, pre)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7d93f4-b593-4079-a7ee-50106af14326",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 模型訓練&結果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8465954-51b1-4f56-9650-9670379c1b3d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 模型、comfort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6a208247-441c-4200-b50e-675371772690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM baseline\n",
      "Accuracy： 0.8261904761904761\n",
      "Recall： 0.72\n",
      "Specificity： 0.8711864406779661\n",
      "Precision： 0.703125\n",
      "f1_score： 0.7114624505928854\n",
      "AUC： 0.795593220338983\n",
      "\n",
      "\n",
      "AdaBoost_model\n",
      "Accuracy： 0.7095238095238096\n",
      "Recall： 0.76\n",
      "Specificity： 0.688135593220339\n",
      "Precision： 0.5080213903743316\n",
      "f1_score： 0.6089743589743589\n",
      "AUC： 0.7240677966101695\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#X_train, y_train, X_test, y_test = data_to_vec(df_value_train, df_value_test)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "SVM_model(df_comfort_train, df_comfort_test)\n",
    "AdaBoost_model(df_comfort_train, df_comfort_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0cc3db-d661-476a-be5d-db61d0e1732a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e7344-f511-4865-a614-4d82d6970b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
