{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "785f65ca-487c-4967-820e-a9f37d809a01",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 資料、套件導入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "119d1d2c-c9e0-42fb-b76f-68f28bf1f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869e40a3-14b4-474d-a26c-27ca17259dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>value</th>\n",
       "      <th>comfort</th>\n",
       "      <th>location</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>service</th>\n",
       "      <th>facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>價格合理 舒適的房間 老闆娘人很好還會自己做早餐給旅客 重點是早餐吃到飽</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>內部房間滿乾淨的，還有大場地，可以讓團體來使用，我覺得很棒</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>隔音還可以，房間不小，但美中不足沒有乾濕分離</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>房子設計的很棒 房間採光很好 大廳挑高氣派 房價合理 台東必住民宿</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cp值高 乾淨舒適空間大 樓下有免費吐司和咖啡 老闆回復速度快</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>港式飲茶餐廳口味很棒，環境乾淨，機車汽車都有停車位，位於高鐵附近，挺適合宴客的。</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>場地氣派、丁香魚酥脆、服務親切 蠟味蘿蔔糕份量多一些更好、牛肉粥好吃</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>交通方便，地下室停車場良好，菜色好，空間設計好，真可說是一流的飯店。</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>地點佳，離逢甲夜市很近，老闆娘很親切服務，房間夠大舒適，浴室也很乾淨</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>房間大 乾淨 價格公道 老闆娘親切 逢甲必推民宿 極推！！！！！！</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1272 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       reviews  value  comfort  location  \\\n",
       "0         價格合理 舒適的房間 老闆娘人很好還會自己做早餐給旅客 重點是早餐吃到飽    1.0      1.0       0.0   \n",
       "1                內部房間滿乾淨的，還有大場地，可以讓團體來使用，我覺得很棒    0.0      0.0       0.0   \n",
       "2                       隔音還可以，房間不小，但美中不足沒有乾濕分離    0.0      1.0       0.0   \n",
       "3            房子設計的很棒 房間採光很好 大廳挑高氣派 房價合理 台東必住民宿    1.0      1.0       0.0   \n",
       "4              Cp值高 乾淨舒適空間大 樓下有免費吐司和咖啡 老闆回復速度快    1.0      1.0       0.0   \n",
       "...                                        ...    ...      ...       ...   \n",
       "1267  港式飲茶餐廳口味很棒，環境乾淨，機車汽車都有停車位，位於高鐵附近，挺適合宴客的。    0.0      0.0       1.0   \n",
       "1268        場地氣派、丁香魚酥脆、服務親切 蠟味蘿蔔糕份量多一些更好、牛肉粥好吃    0.0      0.0       0.0   \n",
       "1269        交通方便，地下室停車場良好，菜色好，空間設計好，真可說是一流的飯店。    0.0      0.0       1.0   \n",
       "1270        地點佳，離逢甲夜市很近，老闆娘很親切服務，房間夠大舒適，浴室也很乾淨    0.0      1.0       1.0   \n",
       "1271         房間大 乾淨 價格公道 老闆娘親切 逢甲必推民宿 極推！！！！！！    1.0      1.0       0.0   \n",
       "\n",
       "      cleanliness  service  facilities  \n",
       "0             0.0      1.0         0.0  \n",
       "1             1.0      0.0         1.0  \n",
       "2             0.0      0.0         0.0  \n",
       "3             0.0      0.0         1.0  \n",
       "4             0.0      1.0         0.0  \n",
       "...           ...      ...         ...  \n",
       "1267          1.0      1.0         1.0  \n",
       "1268          0.0      1.0         0.0  \n",
       "1269          0.0      1.0         1.0  \n",
       "1270          1.0      1.0         0.0  \n",
       "1271          1.0      1.0         0.0  \n",
       "\n",
       "[1272 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../data/0414/review_dataset.csv'\n",
    "df = pd.read_csv(path)\n",
    "df = df[:1272]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5927fc-4120-4d6f-93f1-f46df33c7749",
   "metadata": {},
   "source": [
    "### 移除重複值、空值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "877c5ed2-bb34-46a9-abb9-b552b0f2bfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>value</th>\n",
       "      <th>comfort</th>\n",
       "      <th>location</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>service</th>\n",
       "      <th>facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviews, value, comfort, location, cleanliness, service, facilities]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#印出重複資料\n",
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2648dcbf-521b-4e1a-bf91-714c46830f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1272, 7)\n",
      "(1272, 7)\n"
     ]
    }
   ],
   "source": [
    "#移除重複值\n",
    "print(df.shape)\n",
    "df = df.drop_duplicates() #移除\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1a8975-7dcf-4fbf-9eb1-a156975bfc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>value</th>\n",
       "      <th>comfort</th>\n",
       "      <th>location</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>service</th>\n",
       "      <th>facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [reviews, value, comfort, location, cleanliness, service, facilities]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#印出空值資料\n",
    "df[df.isnull().T.any()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211966e1-99c4-4c45-9564-8eae70384169",
   "metadata": {},
   "source": [
    "### 拆分數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d816dad-7dbe-4d6b-82b0-d358fa3d733e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集： (840, 7)\n",
      "測試集： (420, 7)\n"
     ]
    }
   ],
   "source": [
    "train_df = df[:int(df.shape[0]*(2/3))]\n",
    "test_df = df[int(df.shape[0]*(2/3)):]\n",
    "print(\"訓練集：\",train_df.shape)\n",
    "print(\"測試集：\",test_df.shape)\n",
    "test_df = test_df.reset_index(drop=True) #重新index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23016dd4-e88f-4a95-8f1b-45c8c2a84523",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 資料前處理：移除標點符號、空格"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c12c508f-068c-448c-a631-c6bef2e12367",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_preprocessing(sentence):\n",
    "    #sentence = '很乾淨，停車方便， 住的那天房價很便宜， 房間和外觀都超可愛\\t'\n",
    "    ## 把標點符號、空格拿掉\n",
    "    pattern = re.compile(r'[^\\w]') #匹配字母數字及下劃線\n",
    "    sentence = re.sub(pattern, '', sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c965bb8-9cd3-495a-a2aa-3b8e1059606b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_preprocessing_run(df):\n",
    "    for i, row in df.iterrows():\n",
    "        ifor_val = review_preprocessing(row['reviews']) #資料處理\n",
    "        df.at[i,'reviews'] = ifor_val #更新資料\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a952c71-9169-46a8-8808-303066aef569",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = review_preprocessing_run(train_df)\n",
    "test_df = review_preprocessing_run(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f4cdf2-d352-431a-a45c-ce4b1c0aff96",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 中文分詞+詞性標注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba0cf211-6b30-4224-afb6-d1cc36c91aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckip_transformers.nlp import CkipWordSegmenter, CkipPosTagger\n",
    "import gzip, bz2\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3c505d7-50a8-4808-aabf-11a6558c5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS = True #是否也要一同執行詞性標記\n",
    "KEEP_PUNCTUATION_POS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96238cd3-67bd-4649-8666-a439aa5c1eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing ws driver\n",
      "Done initializing POS driver\n",
      "Initializing pos driver\n"
     ]
    }
   ],
   "source": [
    "device = -1 # 0=GPU, -1=CPU\n",
    "level = 3 #level: 3=most accurate, but model size largest\n",
    "print(\"Initializing ws driver\", flush=True) #flush 實現動態Loading\n",
    "ws_driver  = CkipWordSegmenter(device=device, level=level)\n",
    "if POS:\n",
    "    print(\"Done initializing POS driver\", flush=True)\n",
    "    pos_driver = CkipPosTagger(device=device, level=level)\n",
    "    print(\"Initializing pos driver\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6ca7b1d-9040-4994-b6a6-30b660a26519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ws_pos_review(sentence):\n",
    "    ws  = ws_driver([sentence])\n",
    "    pos = pos_driver(ws) \n",
    "\n",
    "    # 打包結果\n",
    "    assert len(ws[0]) == len(pos[0]) #檢查 ws 和 pos是否長度一致\n",
    "    res = []\n",
    "    for word_ws, word_pos in zip(ws[0], pos[0]):\n",
    "        res.append(f\"{word_ws}({word_pos})\")\n",
    "    \n",
    "    return \",\".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "907c99f1-305b-4324-b4d9-6fad71139d44",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ws_pos_review_run(df):\n",
    "    for i, row in df.iterrows():\n",
    "        ws_pos_list = ws_pos_review(row['reviews']) #分詞+詞性標注\n",
    "        df.at[i,'ws_pos_reviews'] = ws_pos_list #更新資料\n",
    "        print(\"目前進度：\" + str(i))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a646ecf2-1d43-4e5c-b017-865392f76dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.44it/s]\n",
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_16708/27497809.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.at[i,'ws_pos_reviews'] = ws_pos_list #更新資料\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.73it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.42it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.32it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.98it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.22it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.60it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1017.54it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.12it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.91it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 962.00it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 195.61it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.57it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.09it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.83it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.44it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.47it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.48it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 102.92it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 64.48it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.91it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.98it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.83it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.60it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.01it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 132.58it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.42it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.40it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.25it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 228.73it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.88it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 32.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 149.08it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.42it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.43it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.77it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.81it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 65.24it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 66.85it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.48it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 34.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 28.68it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 29.72it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.34it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.47it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.59it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.21it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 27.56it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 32.43it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 32.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.32it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 28.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.94it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 32.43it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 38.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 555.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.25it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.98it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.58it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 26.09it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 64.71it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.22it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 34.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.34it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 25.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.97it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 32.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.61it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 24.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 64.04it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.88it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 28.40it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 95.39it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.02it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.74it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.57it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 33.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 27.45it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 28.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 28.56it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.04it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.72it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.72it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 31.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 33.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 35.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 29.98it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 30.17it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 32.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.14it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.69it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.26it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.44it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.03it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.17it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.09it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.79it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.92it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.96it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.47it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.79it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.53it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.04it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.41it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.75it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.75it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.77it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.12it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.00it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.42it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.69it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.22it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.10it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 995.80it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.22it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.81it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 500.10it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1003.18it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.69it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.69it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.04it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 990.16it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 994.85it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.22it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.17it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.22it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.46it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.46it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.04it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.69it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.40it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.17it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.22it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1003.66it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.27it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.04it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1003.42it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.94it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.01it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.04it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.69it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.81it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1003.42it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.94it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.75it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.17it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.94it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.69it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.69it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1004.38it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.75it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.25it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1006.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.69it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.17it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.22it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.72it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.98it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.28it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.17it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.69it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.72it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1003.42it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.10it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 959.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.75it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.22it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 499.92it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.46it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1003.66it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1003.66it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.17it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.42it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1003.42it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1003.90it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.41it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.22it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.98it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.46it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.85it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.77it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.17it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.88it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 996.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 997.93it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.94it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.78it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.34it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1004.38it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.12it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.81it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.18it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  9.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.17it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.62it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.17it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.35it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.55it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 23.81it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 20.00it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1003.18it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.29it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.07it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.83it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1000.79it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.49it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.15it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.38it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.24it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.33it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 998.64it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.20it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.13it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1002.22it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 17.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.71it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 14.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.36it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 999.60it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 18.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.76it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 12.66it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 15.87it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.70it/s]\n",
      "Tokenization: 100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00, 13.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前進度：419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_df_ws = ws_pos_review_run(train_df)\n",
    "test_df_ws = ws_pos_review_run(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "680c91b8-a54c-4fec-9ea5-57a8339d29ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>value</th>\n",
       "      <th>comfort</th>\n",
       "      <th>location</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>service</th>\n",
       "      <th>facilities</th>\n",
       "      <th>ws_pos_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>價格合理舒適的房間老闆娘人很好還會自己做早餐給旅客重點是早餐吃到飽</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>價格(Na),合理(VH),舒適(VH),的(DE),房間(Nc),老闆娘(Na),人(Na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>內部房間滿乾淨的還有大場地可以讓團體來使用我覺得很棒</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>內部(Ncd),房間(Nc),滿(Dfa),乾淨(VH),的(DE),還(D),有(V_2)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>隔音還可以房間不小但美中不足沒有乾濕分離</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>隔音(A),還可以(D),房間(Nc),不(D),小(VH),但(Cbb),美中不足(VH)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>房子設計的很棒房間採光很好大廳挑高氣派房價合理台東必住民宿</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>房子(Na),設計(VC),的(DE),很(Dfa),棒(VH),房間(Nc),採光(Na)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cp值高乾淨舒適空間大樓下有免費吐司和咖啡老闆回復速度快</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cp值(FW),高(VH),乾淨(VH),舒適(VH),空間(Na),大樓(Na),下(Nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>老闆體貼又親切又有美味早餐吃超推薦</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>老闆(Na),體貼(VJ),又(Caa),親切(VH),又(Caa),有(V_2),美味(V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>平價老闆娘親切但床單似乎不乾淨身體會癢</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>平價(Na),老闆娘(Na),親切(VH),但(Cbb),床單(Na),似乎(D),不(D)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>專業型開飲機有小陽台曬一下衣服隔天就會乾老闆很親切很優的民宿推</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>專業型(Na),開飲機(Na),有(V_2),小(VH),陽台(Na),曬(VJ),一下(N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>房間舒適床很好睡不在鬧區所以摩托車噪音少一覺好眠</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>房間(Nc),舒適(VH),床(Na),很(Dfa),好(VH),睡(VA),不(D),在(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>這家窩旅有提供一個交誼廳的空間能消除沉默彼此打開心分享旅遊經驗與美食分享</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>這(Nep),家(Nf),窩旅(Nb),有(V_2),提供(VD),一(Neu),個(Nf)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>840 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  reviews  value  comfort  location  \\\n",
       "0       價格合理舒適的房間老闆娘人很好還會自己做早餐給旅客重點是早餐吃到飽    1.0      1.0       0.0   \n",
       "1              內部房間滿乾淨的還有大場地可以讓團體來使用我覺得很棒    0.0      0.0       0.0   \n",
       "2                    隔音還可以房間不小但美中不足沒有乾濕分離    0.0      1.0       0.0   \n",
       "3           房子設計的很棒房間採光很好大廳挑高氣派房價合理台東必住民宿    1.0      1.0       0.0   \n",
       "4            Cp值高乾淨舒適空間大樓下有免費吐司和咖啡老闆回復速度快    1.0      1.0       0.0   \n",
       "..                                    ...    ...      ...       ...   \n",
       "835                     老闆體貼又親切又有美味早餐吃超推薦    0.0      0.0       0.0   \n",
       "836                   平價老闆娘親切但床單似乎不乾淨身體會癢    1.0      0.0       0.0   \n",
       "837       專業型開飲機有小陽台曬一下衣服隔天就會乾老闆很親切很優的民宿推    0.0      0.0       0.0   \n",
       "838              房間舒適床很好睡不在鬧區所以摩托車噪音少一覺好眠    0.0      1.0       1.0   \n",
       "839  這家窩旅有提供一個交誼廳的空間能消除沉默彼此打開心分享旅遊經驗與美食分享    0.0      0.0       0.0   \n",
       "\n",
       "     cleanliness  service  facilities  \\\n",
       "0            0.0      1.0         0.0   \n",
       "1            1.0      0.0         1.0   \n",
       "2            0.0      0.0         1.0   \n",
       "3            0.0      0.0         0.0   \n",
       "4            0.0      1.0         0.0   \n",
       "..           ...      ...         ...   \n",
       "835          0.0      1.0         0.0   \n",
       "836          1.0      1.0         0.0   \n",
       "837          0.0      1.0         1.0   \n",
       "838          0.0      0.0         0.0   \n",
       "839          0.0      0.0         1.0   \n",
       "\n",
       "                                        ws_pos_reviews  \n",
       "0    價格(Na),合理(VH),舒適(VH),的(DE),房間(Nc),老闆娘(Na),人(Na...  \n",
       "1    內部(Ncd),房間(Nc),滿(Dfa),乾淨(VH),的(DE),還(D),有(V_2)...  \n",
       "2    隔音(A),還可以(D),房間(Nc),不(D),小(VH),但(Cbb),美中不足(VH)...  \n",
       "3    房子(Na),設計(VC),的(DE),很(Dfa),棒(VH),房間(Nc),採光(Na)...  \n",
       "4    Cp值(FW),高(VH),乾淨(VH),舒適(VH),空間(Na),大樓(Na),下(Nc...  \n",
       "..                                                 ...  \n",
       "835  老闆(Na),體貼(VJ),又(Caa),親切(VH),又(Caa),有(V_2),美味(V...  \n",
       "836  平價(Na),老闆娘(Na),親切(VH),但(Cbb),床單(Na),似乎(D),不(D)...  \n",
       "837  專業型(Na),開飲機(Na),有(V_2),小(VH),陽台(Na),曬(VJ),一下(N...  \n",
       "838  房間(Nc),舒適(VH),床(Na),很(Dfa),好(VH),睡(VA),不(D),在(...  \n",
       "839  這(Nep),家(Nf),窩旅(Nb),有(V_2),提供(VD),一(Neu),個(Nf)...  \n",
       "\n",
       "[840 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8307c5f-0482-4c81-a1d8-19a6b949cc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>value</th>\n",
       "      <th>comfort</th>\n",
       "      <th>location</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>service</th>\n",
       "      <th>facilities</th>\n",
       "      <th>ws_pos_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>而且廚房有提供餅乾飲料可以買其實也可以不用去到全家買</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>而且(Cbb),廚房(Nc),有(V_2),提供(VD),餅乾(Na),飲料(Na),可以(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>而且離車站客運站都很近有機會會想回住</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>而且(Cbb),離(P),車站(Nc),客運站(Nc),都(D),很(Dfa),近(VH),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>離車站好近房間很大隨時訂放都有人接洽雖然不是主題民宿推薦洽公背包客住宿</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>離(P),車站(Nc),好(Dfa),近(VH),房間(Nc),很(Dfa),大(VH),隨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4人房空間超大床埔也大整體乾淨舒適超讚</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4(Neu),人(Na),房(Na),空間(Na),超大(A),床埔(Nc),也(D),大(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>價格公道的背包客民宿老闆也蠻客氣的旁邊還有機車等代步工具可租乘</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>價格(Na),公道(VH),的(DE),背包客(Na),民宿(Nc),老闆(Na),也(D)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>房間就可以看到海馬哥非常熱情民宿風格簡約很多ikea的東西</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>房間(Nc),就(D),可以(D),看到(VE),海馬哥(Nb),非常(Dfa),熱情(VH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>老闆娘還說如果先問可以借嬰兒小推車我們就不用帶了帶小孩吃烤肉必備</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>老闆娘(Na),還(D),說(VE),如果(Cbb),先(D),問(VE),可以(D),借(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>乾淨舒適闆娘和小幫手超熱情推薦在地景點及美食招待的水果好甜好好吃完食</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>乾淨(VH),舒適(VH),闆娘(Na),和(Caa),小(VH),幫手(Na),超(Dfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>老闆娘親切贈予水果點心房間舒適整潔小孩很喜歡</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>老闆娘(Na),親切(VH),贈予(VD),水果(Na),點心(Na),房間(Nc),舒適(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>交通方便地點好近火車站近711房間大床非常舒適價格便宜</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>交通(Na),方便(VH),地點(Na),好(Dfa),近(VJ),火車站(Nc),近(Da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 reviews  value  comfort  location  \\\n",
       "0             而且廚房有提供餅乾飲料可以買其實也可以不用去到全家買    0.0      0.0       0.0   \n",
       "1                     而且離車站客運站都很近有機會會想回住    0.0      0.0       1.0   \n",
       "2    離車站好近房間很大隨時訂放都有人接洽雖然不是主題民宿推薦洽公背包客住宿    0.0      1.0       1.0   \n",
       "3                    4人房空間超大床埔也大整體乾淨舒適超讚    0.0      1.0       0.0   \n",
       "4        價格公道的背包客民宿老闆也蠻客氣的旁邊還有機車等代步工具可租乘    1.0      0.0       0.0   \n",
       "..                                   ...    ...      ...       ...   \n",
       "415        房間就可以看到海馬哥非常熱情民宿風格簡約很多ikea的東西    0.0      0.0       1.0   \n",
       "416     老闆娘還說如果先問可以借嬰兒小推車我們就不用帶了帶小孩吃烤肉必備    0.0      0.0       0.0   \n",
       "417   乾淨舒適闆娘和小幫手超熱情推薦在地景點及美食招待的水果好甜好好吃完食    0.0      1.0       0.0   \n",
       "418               老闆娘親切贈予水果點心房間舒適整潔小孩很喜歡    0.0      1.0       0.0   \n",
       "419          交通方便地點好近火車站近711房間大床非常舒適價格便宜    1.0      1.0       1.0   \n",
       "\n",
       "     cleanliness  service  facilities  \\\n",
       "0            0.0      1.0         0.0   \n",
       "1            0.0      0.0         0.0   \n",
       "2            0.0      1.0         0.0   \n",
       "3            1.0      0.0         0.0   \n",
       "4            0.0      1.0         1.0   \n",
       "..           ...      ...         ...   \n",
       "415          0.0      1.0         1.0   \n",
       "416          0.0      0.0         1.0   \n",
       "417          1.0      1.0         0.0   \n",
       "418          1.0      1.0         0.0   \n",
       "419          0.0      0.0         0.0   \n",
       "\n",
       "                                        ws_pos_reviews  \n",
       "0    而且(Cbb),廚房(Nc),有(V_2),提供(VD),餅乾(Na),飲料(Na),可以(...  \n",
       "1    而且(Cbb),離(P),車站(Nc),客運站(Nc),都(D),很(Dfa),近(VH),...  \n",
       "2    離(P),車站(Nc),好(Dfa),近(VH),房間(Nc),很(Dfa),大(VH),隨...  \n",
       "3    4(Neu),人(Na),房(Na),空間(Na),超大(A),床埔(Nc),也(D),大(...  \n",
       "4    價格(Na),公道(VH),的(DE),背包客(Na),民宿(Nc),老闆(Na),也(D)...  \n",
       "..                                                 ...  \n",
       "415  房間(Nc),就(D),可以(D),看到(VE),海馬哥(Nb),非常(Dfa),熱情(VH...  \n",
       "416  老闆娘(Na),還(D),說(VE),如果(Cbb),先(D),問(VE),可以(D),借(...  \n",
       "417  乾淨(VH),舒適(VH),闆娘(Na),和(Caa),小(VH),幫手(Na),超(Dfa...  \n",
       "418  老闆娘(Na),親切(VH),贈予(VD),水果(Na),點心(Na),房間(Nc),舒適(...  \n",
       "419  交通(Na),方便(VH),地點(Na),好(Dfa),近(VJ),火車站(Nc),近(Da...  \n",
       "\n",
       "[420 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e826f5-5a5a-4cc8-a7bd-3a0ffd9d2f5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 移除停用詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e822b94a-62ab-4fee-bf82-8bec24bd0d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop(df):\n",
    "    df_2 = df #將分詞、詞性標註的結果存到另一個df裡 \n",
    "    stopwords_path='../data/stopwords_TW2.txt' #使用哈工大停用詞表\n",
    "    # 設定停用詞\n",
    "    print('start read stopwords data.')\n",
    "    stopwords = []\n",
    "    with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if len(line)>0:\n",
    "                stopwords.append(line.strip())\n",
    "\n",
    "    rawlist = df_2['ws_pos_reviews'].tolist() \n",
    "\n",
    "    for idx,element in enumerate(rawlist):\n",
    "        filter_list = []\n",
    "        rawlist2 = element.split(\",\") #轉成 list\n",
    "        for val in rawlist2: #去比較list裡面每一個元素，是否屬於stopwords\n",
    "            extract_str = re.search('(.*?)\\(', val).group(1) #擷取\"(\"前面的字串\n",
    "            if(extract_str not in stopwords): # 如果屬於stopwords，就append到新的filter_list\n",
    "                filter_list.append(val)\n",
    "        df_2.at[idx,'filtered'] = \",\".join(filter_list) #更新df_2資料\n",
    "    return df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c14ff0f-d40b-4ead-8225-4d943699ff33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start read stopwords data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_16708/4062774324.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_2.at[idx,'filtered'] = \",\".join(filter_list) #更新df_2資料\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start read stopwords data.\n"
     ]
    }
   ],
   "source": [
    "train_df = remove_stop(train_df_ws)\n",
    "test_df = remove_stop(test_df_ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6ad116-0c88-4863-a4ab-1bbd9f583459",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 存檔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3475a24-801a-4e7e-91de-35de1f79eabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/0407/review_data(seg+pos+stopwords)_train.csv', encoding='utf_8_sig', index=False)\n",
    "test_df.to_csv('../data/0407/review_data(seg+pos+stopwords)_test.csv', encoding='utf_8_sig', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d814611-4a44-45f4-a7e2-b1979fa3bb6b",
   "metadata": {},
   "source": [
    "### 擷取名詞和動詞、外語、介詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10a438f5-0381-48d1-b716-7e50edfb44d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getword(sentence):\n",
    "    #sentence = '價格(Na),合理(VH),舒適(VH),房間(Nc),老闆娘(Na),人(Na),很(Dfa),好(VH),還(D),會(D),做(VC),早餐(Na),旅客(Na),重點(Na),早餐(Na),吃到飽(VC)'\n",
    "    res=[]\n",
    "    pattern = r\"\\b[^,]*\\([N,V,F,P][^,]*\"\n",
    "    matches = re.finditer(pattern, sentence)\n",
    "    for matchNum, match in enumerate(matches, start=1):\n",
    "        res.append(match.group()) #放進list\n",
    "    #將list轉成string\n",
    "    filter_str = ','.join(res)\n",
    "    return filter_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7df5cd48-42eb-404a-bbd3-5ccfcdc816dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\g3190\\AppData\\Local\\Temp/ipykernel_16708/4185028873.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['filtered_word'] = train_df.apply(lambda x: getword(x['filtered']),axis=1)\n"
     ]
    }
   ],
   "source": [
    "train_df['filtered_word'] = train_df.apply(lambda x: getword(x['filtered']),axis=1)\n",
    "test_df['filtered_word'] = test_df.apply(lambda x: getword(x['filtered']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d464d10d-0d66-4061-a4f7-8f20394301c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>value</th>\n",
       "      <th>comfort</th>\n",
       "      <th>location</th>\n",
       "      <th>cleanliness</th>\n",
       "      <th>service</th>\n",
       "      <th>facilities</th>\n",
       "      <th>ws_pos_reviews</th>\n",
       "      <th>filtered</th>\n",
       "      <th>filtered_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>而且廚房有提供餅乾飲料可以買其實也可以不用去到全家買</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>而且(Cbb),廚房(Nc),有(V_2),提供(VD),餅乾(Na),飲料(Na),可以(...</td>\n",
       "      <td>廚房(Nc),提供(VD),餅乾(Na),飲料(Na),買(VC),不用(D),全(Neqa...</td>\n",
       "      <td>廚房(Nc),提供(VD),餅乾(Na),飲料(Na),買(VC),全(Neqa),家(Nc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>而且離車站客運站都很近有機會會想回住</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>而且(Cbb),離(P),車站(Nc),客運站(Nc),都(D),很(Dfa),近(VH),...</td>\n",
       "      <td>離(P),車站(Nc),客運站(Nc),機會(Na),想(VE),回住(VCL)</td>\n",
       "      <td>離(P),車站(Nc),客運站(Nc),機會(Na),想(VE),回住(VCL)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>離車站好近房間很大隨時訂放都有人接洽雖然不是主題民宿推薦洽公背包客住宿</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>離(P),車站(Nc),好(Dfa),近(VH),房間(Nc),很(Dfa),大(VH),隨...</td>\n",
       "      <td>離(P),車站(Nc),好(Dfa),房間(Nc),隨時(D),訂放(VC),人(Na),接...</td>\n",
       "      <td>離(P),車站(Nc),房間(Nc),訂放(VC),人(Na),接洽(VC),主題(Na),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4人房空間超大床埔也大整體乾淨舒適超讚</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4(Neu),人(Na),房(Na),空間(Na),超大(A),床埔(Nc),也(D),大(...</td>\n",
       "      <td>人(Na),房(Na),空間(Na),超大(A),床埔(Nc),整體(Na),乾淨(VH),...</td>\n",
       "      <td>人(Na),房(Na),空間(Na),床埔(Nc),整體(Na),乾淨(VH),舒適(VH)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>價格公道的背包客民宿老闆也蠻客氣的旁邊還有機車等代步工具可租乘</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>價格(Na),公道(VH),的(DE),背包客(Na),民宿(Nc),老闆(Na),也(D)...</td>\n",
       "      <td>價格(Na),公道(VH),背包客(Na),民宿(Nc),老闆(Na),客氣(VH),旁邊(...</td>\n",
       "      <td>價格(Na),公道(VH),背包客(Na),民宿(Nc),老闆(Na),客氣(VH),旁邊(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>房間就可以看到海馬哥非常熱情民宿風格簡約很多ikea的東西</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>房間(Nc),就(D),可以(D),看到(VE),海馬哥(Nb),非常(Dfa),熱情(VH...</td>\n",
       "      <td>房間(Nc),看到(VE),海馬哥(Nb),熱情(VH),民宿(Nc),風格(Na),簡約(...</td>\n",
       "      <td>房間(Nc),看到(VE),海馬哥(Nb),熱情(VH),民宿(Nc),風格(Na),簡約(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>老闆娘還說如果先問可以借嬰兒小推車我們就不用帶了帶小孩吃烤肉必備</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>老闆娘(Na),還(D),說(VE),如果(Cbb),先(D),問(VE),可以(D),借(...</td>\n",
       "      <td>老闆娘(Na),說(VE),先(D),問(VE),嬰兒(Na),小推車(VH),不用(D),...</td>\n",
       "      <td>老闆娘(Na),說(VE),問(VE),嬰兒(Na),小推車(VH),小孩(Na),吃(VC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>乾淨舒適闆娘和小幫手超熱情推薦在地景點及美食招待的水果好甜好好吃完食</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>乾淨(VH),舒適(VH),闆娘(Na),和(Caa),小(VH),幫手(Na),超(Dfa...</td>\n",
       "      <td>乾淨(VH),舒適(VH),闆娘(Na),小(VH),幫手(Na),超(Dfa),熱情(VH...</td>\n",
       "      <td>乾淨(VH),舒適(VH),闆娘(Na),小(VH),幫手(Na),熱情(VH),推薦(VC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>老闆娘親切贈予水果點心房間舒適整潔小孩很喜歡</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>老闆娘(Na),親切(VH),贈予(VD),水果(Na),點心(Na),房間(Nc),舒適(...</td>\n",
       "      <td>老闆娘(Na),親切(VH),贈予(VD),水果(Na),點心(Na),房間(Nc),舒適(...</td>\n",
       "      <td>老闆娘(Na),親切(VH),贈予(VD),水果(Na),點心(Na),房間(Nc),舒適(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>交通方便地點好近火車站近711房間大床非常舒適價格便宜</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>交通(Na),方便(VH),地點(Na),好(Dfa),近(VJ),火車站(Nc),近(Da...</td>\n",
       "      <td>交通(Na),方便(VH),地點(Na),好(Dfa),火車站(Nc),711(Neu),房...</td>\n",
       "      <td>交通(Na),方便(VH),地點(Na),火車站(Nc),711(Neu),房間(Nc),床...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 reviews  value  comfort  location  \\\n",
       "0             而且廚房有提供餅乾飲料可以買其實也可以不用去到全家買    0.0      0.0       0.0   \n",
       "1                     而且離車站客運站都很近有機會會想回住    0.0      0.0       1.0   \n",
       "2    離車站好近房間很大隨時訂放都有人接洽雖然不是主題民宿推薦洽公背包客住宿    0.0      1.0       1.0   \n",
       "3                    4人房空間超大床埔也大整體乾淨舒適超讚    0.0      1.0       0.0   \n",
       "4        價格公道的背包客民宿老闆也蠻客氣的旁邊還有機車等代步工具可租乘    1.0      0.0       0.0   \n",
       "..                                   ...    ...      ...       ...   \n",
       "415        房間就可以看到海馬哥非常熱情民宿風格簡約很多ikea的東西    0.0      0.0       1.0   \n",
       "416     老闆娘還說如果先問可以借嬰兒小推車我們就不用帶了帶小孩吃烤肉必備    0.0      0.0       0.0   \n",
       "417   乾淨舒適闆娘和小幫手超熱情推薦在地景點及美食招待的水果好甜好好吃完食    0.0      1.0       0.0   \n",
       "418               老闆娘親切贈予水果點心房間舒適整潔小孩很喜歡    0.0      1.0       0.0   \n",
       "419          交通方便地點好近火車站近711房間大床非常舒適價格便宜    1.0      1.0       1.0   \n",
       "\n",
       "     cleanliness  service  facilities  \\\n",
       "0            0.0      1.0         0.0   \n",
       "1            0.0      0.0         0.0   \n",
       "2            0.0      1.0         0.0   \n",
       "3            1.0      0.0         0.0   \n",
       "4            0.0      1.0         1.0   \n",
       "..           ...      ...         ...   \n",
       "415          0.0      1.0         1.0   \n",
       "416          0.0      0.0         1.0   \n",
       "417          1.0      1.0         0.0   \n",
       "418          1.0      1.0         0.0   \n",
       "419          0.0      0.0         0.0   \n",
       "\n",
       "                                        ws_pos_reviews  \\\n",
       "0    而且(Cbb),廚房(Nc),有(V_2),提供(VD),餅乾(Na),飲料(Na),可以(...   \n",
       "1    而且(Cbb),離(P),車站(Nc),客運站(Nc),都(D),很(Dfa),近(VH),...   \n",
       "2    離(P),車站(Nc),好(Dfa),近(VH),房間(Nc),很(Dfa),大(VH),隨...   \n",
       "3    4(Neu),人(Na),房(Na),空間(Na),超大(A),床埔(Nc),也(D),大(...   \n",
       "4    價格(Na),公道(VH),的(DE),背包客(Na),民宿(Nc),老闆(Na),也(D)...   \n",
       "..                                                 ...   \n",
       "415  房間(Nc),就(D),可以(D),看到(VE),海馬哥(Nb),非常(Dfa),熱情(VH...   \n",
       "416  老闆娘(Na),還(D),說(VE),如果(Cbb),先(D),問(VE),可以(D),借(...   \n",
       "417  乾淨(VH),舒適(VH),闆娘(Na),和(Caa),小(VH),幫手(Na),超(Dfa...   \n",
       "418  老闆娘(Na),親切(VH),贈予(VD),水果(Na),點心(Na),房間(Nc),舒適(...   \n",
       "419  交通(Na),方便(VH),地點(Na),好(Dfa),近(VJ),火車站(Nc),近(Da...   \n",
       "\n",
       "                                              filtered  \\\n",
       "0    廚房(Nc),提供(VD),餅乾(Na),飲料(Na),買(VC),不用(D),全(Neqa...   \n",
       "1             離(P),車站(Nc),客運站(Nc),機會(Na),想(VE),回住(VCL)   \n",
       "2    離(P),車站(Nc),好(Dfa),房間(Nc),隨時(D),訂放(VC),人(Na),接...   \n",
       "3    人(Na),房(Na),空間(Na),超大(A),床埔(Nc),整體(Na),乾淨(VH),...   \n",
       "4    價格(Na),公道(VH),背包客(Na),民宿(Nc),老闆(Na),客氣(VH),旁邊(...   \n",
       "..                                                 ...   \n",
       "415  房間(Nc),看到(VE),海馬哥(Nb),熱情(VH),民宿(Nc),風格(Na),簡約(...   \n",
       "416  老闆娘(Na),說(VE),先(D),問(VE),嬰兒(Na),小推車(VH),不用(D),...   \n",
       "417  乾淨(VH),舒適(VH),闆娘(Na),小(VH),幫手(Na),超(Dfa),熱情(VH...   \n",
       "418  老闆娘(Na),親切(VH),贈予(VD),水果(Na),點心(Na),房間(Nc),舒適(...   \n",
       "419  交通(Na),方便(VH),地點(Na),好(Dfa),火車站(Nc),711(Neu),房...   \n",
       "\n",
       "                                         filtered_word  \n",
       "0    廚房(Nc),提供(VD),餅乾(Na),飲料(Na),買(VC),全(Neqa),家(Nc...  \n",
       "1             離(P),車站(Nc),客運站(Nc),機會(Na),想(VE),回住(VCL)  \n",
       "2    離(P),車站(Nc),房間(Nc),訂放(VC),人(Na),接洽(VC),主題(Na),...  \n",
       "3       人(Na),房(Na),空間(Na),床埔(Nc),整體(Na),乾淨(VH),舒適(VH)  \n",
       "4    價格(Na),公道(VH),背包客(Na),民宿(Nc),老闆(Na),客氣(VH),旁邊(...  \n",
       "..                                                 ...  \n",
       "415  房間(Nc),看到(VE),海馬哥(Nb),熱情(VH),民宿(Nc),風格(Na),簡約(...  \n",
       "416  老闆娘(Na),說(VE),問(VE),嬰兒(Na),小推車(VH),小孩(Na),吃(VC...  \n",
       "417  乾淨(VH),舒適(VH),闆娘(Na),小(VH),幫手(Na),熱情(VH),推薦(VC...  \n",
       "418  老闆娘(Na),親切(VH),贈予(VD),水果(Na),點心(Na),房間(Nc),舒適(...  \n",
       "419  交通(Na),方便(VH),地點(Na),火車站(Nc),711(Neu),房間(Nc),床...  \n",
       "\n",
       "[420 rows x 10 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6b08f7c-7f57-4bbd-87a6-e6bbb39edd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/0407/review_data(seg+pos+stopwords)_train_n+v+f+p.csv', encoding='utf_8_sig', index=False)\n",
    "test_df.to_csv('../data/0407/review_data(seg+pos+stopwords)_test_n+v+f+p.csv', encoding='utf_8_sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e15f53-9532-439a-ae5d-5193b7c83479",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (NLP)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
